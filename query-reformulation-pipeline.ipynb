{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Reformulation \n",
    "Step by step building a custom pipeline to handle queries for Twitter database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download one of the predefined German models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select german package\n",
    "MODEL = 'de_core_news_lg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load german language model\n",
    "nlp = spacy.load(MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a user query to test the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"Ist die große Koalition gescheitert unter Merkel? #Groko#SPD#CDU\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Tokens from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ist', 'die', 'große', 'Koalition', 'gescheitert', 'unter', 'Merkel', '?', '#', 'Groko#SPD#CDU']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "print([token.text for token in doc])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preprocessing\n",
    "Hashtags are treated poorly. Detect them and prevent the tokenizer from splitting them.\n",
    "- don't split hashtag and it's text\n",
    "- split compound hashtags\n",
    "- mark hashtags in SpaCy\n",
    "\n",
    "The user mentions are kept as one token. \n",
    "- mark them as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer\n",
    "Modify the tokenizer such that hashtags are not split at `#`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "import re\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n",
    "# overwrite token_match function of the tokenizer\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ist', 'die', 'große', 'Koalition', 'gescheitert', 'unter', 'Merkel', '?', '#Groko#SPD#CDU']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure the whitespaces are set correctly in between the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ist', 'die', 'große', 'Koalition', 'gescheitert', 'unter', 'Merkel', '?', '#Groko', '#SPD', '#CDU']\n"
     ]
    }
   ],
   "source": [
    "def seperate_hashtags(text: str):\n",
    "    \"\"\"\n",
    "    Insert a whitespace if hashtags are missing a gap in between.  \n",
    "    \"\"\"\n",
    "    for i, j in enumerate(text):\n",
    "        if (text[i] == \"#\" and i > 0):\n",
    "            if text[i-1] != \" \":\n",
    "                    text = text[:i] + \" \" + text[i:]\n",
    "                    i+=1\n",
    "    return text\n",
    "\n",
    "QUERY = seperate_hashtags(QUERY)\n",
    "\n",
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Matcher\n",
    "Customize the Matcher to handle Tweet-specific syntax - i.e. hashtags.\n",
    "- Mark Hashtag (#)\n",
    "- Mark Twitter User (@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.user_matcher.UserMatcher at 0x7f7f6776f670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hashtag_matcher import create_hashtag_matcher\n",
    "from src.user_matcher import create_user_matcher\n",
    "\n",
    "nlp.add_pipe(\"hashtag_matcher\") \n",
    "nlp.add_pipe(\"user_matcher\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ist</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>große</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gescheitert</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unter</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Groko</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text  is_hashtag\n",
       "0           Ist       False\n",
       "1           die       False\n",
       "2         große       False\n",
       "3     Koalition       False\n",
       "4   gescheitert       False\n",
       "5         unter       False\n",
       "6        Merkel       False\n",
       "7             ?       False\n",
       "8        #Groko        True\n",
       "9          #SPD        True\n",
       "10         #CDU        True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_hashtag])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ist</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>große</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gescheitert</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unter</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Groko</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text  is_user\n",
       "0           Ist    False\n",
       "1           die    False\n",
       "2         große    False\n",
       "3     Koalition    False\n",
       "4   gescheitert    False\n",
       "5         unter    False\n",
       "6        Merkel    False\n",
       "7             ?    False\n",
       "8        #Groko    False\n",
       "9          #SPD    False\n",
       "10         #CDU    False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_user])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_user\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Named Entities\n",
    "How are named entities detected? Especially those that are hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NER Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Text, NER Label]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    data.append([ent.text, spacy.explain(ent.label_)])\n",
    "    \n",
    "# displacy.render(doc, style=\"ent\")\n",
    "pd.DataFrame(data, columns=[\"Text\", \"NER Label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that named entities are treated not optimally. Sometimes named entities aren't detected or the corresponding tokens don't make sense. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>UPOS Tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactics</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha Token</th>\n",
       "      <th>Stop Token</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ist</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>große</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>sb</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gescheitert</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>pd</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unter</td>\n",
       "      <td>ADP</td>\n",
       "      <td>APPR</td>\n",
       "      <td>mo</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>$.</td>\n",
       "      <td>punct</td>\n",
       "      <td>?</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#Groko</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#Xxxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text UPOS Tag    Tag Syntactics   Shape  Alpha Token  Stop Token  \\\n",
       "0           Ist      AUX  VAFIN       ROOT     Xxx         True        True   \n",
       "1           die      DET    ART         nk     xxx         True        True   \n",
       "2         große      ADJ   ADJA         nk    xxxx         True        True   \n",
       "3     Koalition     NOUN     NN         sb   Xxxxx         True       False   \n",
       "4   gescheitert     VERB  VVFIN         pd    xxxx         True       False   \n",
       "5         unter      ADP   APPR         mo    xxxx         True        True   \n",
       "6        Merkel    PROPN     NE         nk   Xxxxx         True       False   \n",
       "7             ?    PUNCT     $.      punct       ?        False       False   \n",
       "8        #Groko    PROPN     NE         nk  #Xxxxx        False       False   \n",
       "9          #SPD     NOUN     NN       ROOT    #XXX        False       False   \n",
       "10         #CDU    PROPN     NE       ROOT    #XXX        False       False   \n",
       "\n",
       "    Hashtag   User  \n",
       "0     False  False  \n",
       "1     False  False  \n",
       "2     False  False  \n",
       "3     False  False  \n",
       "4     False  False  \n",
       "5     False  False  \n",
       "6     False  False  \n",
       "7     False  False  \n",
       "8      True  False  \n",
       "9      True  False  \n",
       "10     True  False  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append ([token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, token._.is_hashtag, token._.is_user])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Text\", \"UPOS Tag\", \"Tag\", \"Syntactics\", \"Shape\", \"Alpha Token\", \"Stop Token\", \"Hashtag\", \"User\"], index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Candidate Selection\n",
    "Extract terms that are used to find synonyms. The words to find synonyms for should be:\n",
    "- verbs or nouns\n",
    "- no hashtags or users\n",
    "- only alphabet characters\n",
    "- no e-mail, URLs or currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidate_terms(doc: spacy.tokens.doc.Doc, pos_tags):\n",
    "    \"\"\"\n",
    "    Select the tokens that should be used for finding similar terms.\n",
    "    \"\"\"\n",
    "    candidate_terms = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_tags:\n",
    "            continue\n",
    "\n",
    "        if token._.is_hashtag is True:\n",
    "            continue\n",
    "\n",
    "        if token._.is_user is True:\n",
    "            continue\n",
    "\n",
    "        if token.is_alpha is False:\n",
    "            continue\n",
    "\n",
    "        #if token.is_stop:\n",
    "        #    continue\n",
    "\n",
    "        if token.like_email:\n",
    "            continue\n",
    "\n",
    "        if token.like_url:\n",
    "            continue\n",
    "\n",
    "        if token.is_currency:\n",
    "            continue\n",
    "\n",
    "        # lemmatize token via ES query pattern\n",
    "        # token.lemma_\n",
    "\n",
    "        candidate_terms.append(token.text)\n",
    "    \n",
    "    return candidate_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['große', 'Koalition', 'gescheitert', 'Merkel']\n"
     ]
    }
   ],
   "source": [
    "pos_tags = [\"VERB\", \"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "candidate_terms = select_candidate_terms(doc, pos_tags)\n",
    "\n",
    "print(candidate_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word Embeddings\n",
    "The following embeddings are applied to the selected terms\n",
    "- FastText\n",
    "- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of most similar words (synonyms) \n",
    "NUM_SIM_TERMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FastText model with **FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.load_model('data/fasttext/cc.de.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'große': ['größere', 'grosse', 'riesengroße'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'gescheitert': ['scheitert', 'Gescheitert', 'gescheitert.'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "ft_synonyms = {}\n",
    "\n",
    "# obtain candidate terms and store them in a json object\n",
    "for term in candidate_terms:\n",
    "    synonyms = ft_model.get_nearest_neighbors(term, k=NUM_SIM_TERMS)\n",
    "    ft_synonyms[f\"{term}\"] = [n[1] for n in synonyms]\n",
    "    \n",
    "print(ft_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastText module gives pretty fancy results. Even out-of-vocabulary words are treated well as expected.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Word2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Word2Vec model via **Gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gensim_w2v_model = KeyedVectors.load_word2vec_format(fname=\"data/devmount/german.model\", no_header=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'große' does not appear in this model\n",
      "{'Koalition': ['Grosse Koalition', 'Grossen Koalition', 'Regierungskoalition'], 'gescheitert': ['scheitert', 'Gescheitert', 'scheitern'], 'Merkel': ['Kanzlerin Merkel', 'Merkel CDU', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "w2v_synonyms = {}\n",
    "\n",
    "# obtain candidate terms and store them in a json object\n",
    "for term in candidate_terms:\n",
    "    if not gensim_w2v_model.has_index_for(term):\n",
    "        print(f\"The word '{term}' does not appear in this model\")\n",
    "    else:\n",
    "        synonyms = gensim_w2v_model.most_similar(term)[:NUM_SIM_TERMS]\n",
    "        w2v_synonyms[f\"{term}\"] = [n[0].replace(\"_\",\" \") for n in synonyms]\n",
    "\n",
    "print(w2v_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gensim_w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lemmatize the terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model seems to work properly. However, it is case-sensitive and may requires to lemmatize the terms. Otherwise the model can't find the correct word vector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Elastic Search\n",
    "\n",
    "Finally, the obtained terms are used to retrieve Tweets from the Elastic Search index. Beforehand, the most relevant expansion terms must be determined. For this purpose, the [Adjacency Matrix Aggregations](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-adjacency-matrix-aggregation.html) are utilized. Afterwards, the hashtags, twitter users and entities are prepared. Given the final expansion terms, the Elastic Search template is loaded and the query is executed on the specified `INDEX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from src.utils import es_connect\n",
    "\n",
    "import json\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('auth/es-credentials.ini')\n",
    "\n",
    "es_client = es_connect(credentials=config[\"ELASTIC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the Elastic Search index \n",
    "INDEX = \"tweets_10\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.1 Aggregation Query\n",
    "Now, it must be determined which of the terms of the initial query should be replaced or used to expand the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the predefined aggregation query\n",
    "es_agg_query = json.load(open('config/es-aggregation.conf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test purposes use a predefined list of synonyms\n",
    "ft_synonyms = {'große': ['größere', 'grosse', 'riesengroße'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = es_agg_query[\"aggs\"][\"interactions\"][\"adjacency_matrix\"][\"filters\"]\n",
    "\n",
    "for term in candidate_terms:\n",
    "    for synonym in ft_synonyms[term]:\n",
    "        filters[term+\"+\"+synonym] = { \"terms\" : { \"txt\" : [term.lower(), synonym.lower()] }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 7 ms\n",
      "\n",
      "('Merkel+Kanzlerin', 2961)\n",
      "('Merkel+Bundeskanzlerin', 2763)\n",
      "('Merkel+Bundeskanzlerin&Merkel+Kanzlerin', 2528)\n",
      "('Merkel+Bundeskanzlerin&Merkel+Merkels', 2527)\n",
      "('Merkel+Kanzlerin&Merkel+Merkels', 2527)\n",
      "('Merkel+Merkels', 2527)\n",
      "('Koalition+Regierungskoalition', 2368)\n",
      "('Koalition+Koalitionspartei', 2299)\n",
      "('Koalition+Koalitionspartei&Koalition+Koalitionsrunde', 2297)\n",
      "('Koalition+Koalitionspartei&Koalition+Regierungskoalition', 2297)\n",
      "('Koalition+Koalitionsrunde', 2297)\n",
      "('Koalition+Koalitionsrunde&Koalition+Regierungskoalition', 2297)\n",
      "('Koalition+Koalitionspartei&Merkel+Bundeskanzlerin', 39)\n",
      "('Koalition+Koalitionsrunde&Merkel+Bundeskanzlerin', 39)\n",
      "('Koalition+Regierungskoalition&Merkel+Bundeskanzlerin', 39)\n",
      "('große+grosse', 35)\n",
      "('Koalition+Koalitionspartei&Merkel+Kanzlerin', 33)\n",
      "('Koalition+Koalitionsrunde&Merkel+Kanzlerin', 33)\n",
      "('Koalition+Regierungskoalition&Merkel+Kanzlerin', 33)\n",
      "('Koalition+Koalitionspartei&Merkel+Merkels', 32)\n",
      "('Koalition+Koalitionsrunde&Merkel+Merkels', 32)\n",
      "('Koalition+Regierungskoalition&Merkel+Merkels', 32)\n",
      "('Merkel+Bundeskanzlerin&große+grosse', 1)\n",
      "('Merkel+Kanzlerin&große+grosse', 1)\n",
      "('Merkel+Merkels&große+grosse', 1)\n"
     ]
    }
   ],
   "source": [
    "# execute the search aggregation query\n",
    "res = es_client.search(index=INDEX, size=es_agg_query[\"size\"], aggregations=es_agg_query[\"aggs\"])\n",
    "\n",
    "# get the aggregations and their score from the response\n",
    "aggregations = [(t[\"key\"], t[\"doc_count\"]) for t in res[\"aggregations\"][\"interactions\"][\"buckets\"]]\n",
    "\n",
    "# sort the aggregations based on their score\n",
    "aggregations.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"Took\",res[\"took\"],\"ms\\n\")\n",
    "for agg in aggregations:\n",
    "    print(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the 'best' expansion terms\n",
    "expansion_terms = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Preparation\n",
    "Obtain a list of Hashtags, Twitter Users and Entities that are included in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = [t.text.lower() for t in doc if t._.is_hashtag ]\n",
    "\n",
    "pd.DataFrame(hashtags, columns=[\"Hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [t.text.lower() for t in doc if t._.is_user ]\n",
    "\n",
    "pd.DataFrame(users, columns=[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [ent.text.lower() for ent in doc.ents]\n",
    "\n",
    "pd.DataFrame(entities, columns=[\"Entity\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Query Formulation \n",
    "Finally, the resulting terms must be arranged in an Elastic Search query. Define a pattern to retrieve relevant tweets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a pattern for an Elastic Search query with\n",
    "- boolean operators (`AND`, `OR`)\n",
    "- boosting  `^`\n",
    "- filter\n",
    "\n",
    "The following Hyperparameters are set in order to modify the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are retweets allowed?\n",
    "RETWEET = False\n",
    "\n",
    "# How much is the matching of hashtags boosted? \n",
    "HASHTAG_BOOST = None\n",
    "\n",
    "# Range of Tweets to be included (FROM, TO)\n",
    "TWEET_RANGE = (\"2021-01-01\", \"2023-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-configured template for an elastic search query\n",
    "query_template = json.load(open('config/es-query.conf'))\n",
    "query = query_template['query']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set if retweets are allowed\n",
    "if RETWEET:\n",
    "    del query['bool']['must_not']['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for testing I use candidate terms which are not yet applied to word embeddings\n",
    "query['bool']['should']['query_string']['query'] = ' '.join(candidate_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the hashtags if present in initial user query\n",
    "if len(hashtags) > 0 :\n",
    "    query['bool']['must']['terms_set']['hashtags']['terms'] = [h[1:].lower() for h in hashtags]\n",
    "else:\n",
    "    del query['bool']['must']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HASHTAG_BOOST is not None:\n",
    "    query['bool']['should']['query_string'][\"fields\"][1] += f\"^{HASHTAG_BOOST}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "for entity in entities:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range for tweets\n",
    "query['bool']['filter'][0]['range']['created_at']['gte'] = TWEET_RANGE[0]\n",
    "query['bool']['filter'][1]['range']['created_at']['lte'] = TWEET_RANGE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'große Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags'],\n",
       "    'default_operator': 'OR'}},\n",
       "  'must': {'terms_set': {'hashtags': {'terms': ['groko', 'cdu', 'spd'],\n",
       "     'minimum_should_match_script': {'source': 'Math.min(params.num_terms, 1)'}}}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': '2021-01-01'}}},\n",
       "   {'range': {'created_at': {'lte': '2023-01-01'}}}]}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Query\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the final Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 3617 hits in 25ms \n",
      "\n",
      "Tweet 0 \n",
      " {'retweet_count': 28, 'reply_count': 7, 'like_count': 191, 'created_at': '2021-09-02T20:44:54+02:00', 'txt': 'Das Versagen der #GroKo #cdu #spd in einem Tweet \\n👎🏼Parteitaktik über alles \\n👎🏼in 4 J. keine wirkliche Reform hinbekommen\\n👎🏼 Oppositionsvorschl. wie immer abgelehnt \\n\\n👎🏼👎🏼 Konsequenz: evtl über 900 MdB inkl. riesiger Kosten &amp; Chaos https://t.co/K9s1T8dVH5', 'hashtags': ['spd', 'cdu', 'groko'], 'word_count': 35} \n",
      "\n",
      "Tweet 1 \n",
      " {'retweet_count': 42, 'reply_count': 17, 'like_count': 350, 'created_at': '2021-08-29T15:25:10+02:00', 'txt': 'Von den letzten 16 Jahren hat die #SPD 12 Jahre mit der #CDU regiert. Die #SPD hat Scholz mit großem Getöse nicht zum Parteivorsitzenden gewählt,mit dem Argument,er stünde für die #GroKo Jetzt ist er Kanzlerkandidat und kokettiert offen damit merkellike zu sein.Die Wahrheit ist:', 'hashtags': ['spd', 'spd', 'cdu', 'groko'], 'word_count': 44} \n",
      "\n",
      "Tweet 2 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'created_at': '2021-09-01T14:26:57+02:00', 'txt': 'Sätze die formal korrekt sind aber halt auch Bekenntnisse.\\n\\n“Und wir [Wer? Politik? Boomer?] müssen auch noch mehr [weil ihr das schon so viel tut?] mit der jüngeren Generation [weil nur die sich fürs Klima interessiert 🤔] sprechen.” [zuhören! Ernst nehmen! Handel!]\\n#SPD #GroKo https://t.co/cA0tCDzFYA', 'hashtags': ['spd', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 3 \n",
      " {'retweet_count': 21, 'reply_count': 1, 'like_count': 84, 'created_at': '2021-08-17T13:24:53+02:00', 'txt': \"Die #GroKo hat nie ambitionierte Klimaziele definiert, aber selbst die erreicht sie nicht: 2021 wird's den höchsten Anstieg der CO2-Emissionen seit 1990 geben. Gesamt- &amp; Sektorziele (Industrie, Gebäude, Verkehr) werden gerissen. Klimaschutz muss man machen, nicht nur ankündigen! https://t.co/sKXsYmqryZ\", 'hashtags': ['groko'], 'word_count': 39} \n",
      "\n",
      "Tweet 4 \n",
      " {'retweet_count': 2, 'reply_count': 0, 'like_count': 7, 'created_at': '2021-10-15T11:48:48+02:00', 'txt': 'Millionen Fördergelder in den Wind geschossen: An diesem unglaublichen Vorgang sieht man, welchen geringen Stellenwert der ländliche Raum für die Niedersachen-#GroKo aus #SPD und #CDU hat. https://t.co/LsFfmDqvNA', 'hashtags': ['spd', 'cdu', 'groko'], 'word_count': 27} \n",
      "\n",
      "Tweet 5 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 3, 'created_at': '2021-10-09T11:34:54+02:00', 'txt': 'Grüne u rote Jugend wissen was sie wollen. Eine 🚥-Koalition oder eine Bundesregierung, die gemeinsam gestaltet, gehören wohl nicht dazu. Ach, bleibt doch bei der #Groko, dann könnt ihr weiter nach Herzenslust gegen was auch immer protestieren.', 'hashtags': ['groko'], 'word_count': 37} \n",
      "\n",
      "Tweet 6 \n",
      " {'retweet_count': 49, 'reply_count': 41, 'like_count': 435, 'created_at': '2021-09-05T17:39:20+02:00', 'txt': 'Da Herr #Söder vor einem Linksrutsch warnt, der größte Linksrutsch fand unter den #Groko-Regierungen unter Angela #Merkel statt. ☝️🤔\\n👉Sie war die beste #CDU-Kanzlerin, welche die #SPD je hatte.🤷\\u200d♂️ https://t.co/UwrxHT8yDu', 'hashtags': ['spd', 'cdu', 'söder', 'merkel', 'groko'], 'word_count': 29} \n",
      "\n",
      "Tweet 7 \n",
      " {'retweet_count': 14, 'reply_count': 1, 'like_count': 194, 'created_at': '2021-09-21T23:18:17+02:00', 'txt': 'Was sind das für Winkelzüge? ihr/du koaliert mit der Union, die @HGMaassen im Ministerium hatte. \\n\\nDa ist wohl wieder der alte @Karl_Lauterbach der als erster gekippt ist und für die #GroKo war und jetzt gegen RotGrünRot wettert. https://t.co/G67HPzKP5h', 'hashtags': ['groko'], 'word_count': 38} \n",
      "\n",
      "Tweet 8 \n",
      " {'retweet_count': 2, 'reply_count': 1, 'like_count': 44, 'created_at': '2021-09-12T11:26:13+02:00', 'txt': '@DierkHirschel @CDU @CSU Richtig ! Aber der Abbau mit der Agenda 2010 mit Hartz mit Riester etc. war leider auch einer der #spd und in den vielen Jahren in der #GroKo standen sie wirklich häufig auf der falschen Seite', 'hashtags': ['spd', 'groko'], 'word_count': 39} \n",
      "\n",
      "Tweet 9 \n",
      " {'retweet_count': 13, 'reply_count': 3, 'like_count': 54, 'created_at': '2021-09-24T13:17:08+02:00', 'txt': 'Die BTW21 wird knapp. Meine drei Argumente für die #SPD: 1. die SPD hat klare Ziele: Mindestlohn, stabile Renten, co2-Neutrale Wirtschaft, 2.Die SPD hat den besseren Kanzlerkandidaten. 3. Die einmalig ideenlose und niederträchtige Kampagne der #CDU darf nicht belohnt werden. https://t.co/mATcCTGbx3', 'hashtags': ['spd', 'cdu'], 'word_count': 41} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = es_client.search(index=INDEX, size=query_template['size'], query=query)\n",
    "\n",
    "print(f'Total of {res[\"hits\"][\"total\"][\"value\"]} hits in {res[\"took\"]}ms \\n')\n",
    "\n",
    "for i, doc in enumerate(res[\"hits\"][\"hits\"]):\n",
    "    print(\"Tweet\", i, \"\\n\", doc[\"_source\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
