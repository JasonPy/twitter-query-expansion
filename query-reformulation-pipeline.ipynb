{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Reformulation \n",
    "Step by step building a custom pipeline to handle queries for Twitter database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download one of the predefined German models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select german package\n",
    "MODEL = 'de_core_news_lg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load german language model\n",
    "nlp = spacy.load(MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a user query to test the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"@amthor gro√üe Koalition Merkel #GroKo #CDU#SPD\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Tokens from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'gro√üe', 'Koalition', 'Merkel', '#', 'GroKo', '#', 'CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "print([token.text for token in doc])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preprocessing\n",
    "Hashtags are treated poorly. Detect them and prevent the tokenizer from splitting them.\n",
    "- don't split hashtag and it's text\n",
    "- split compound hashtags\n",
    "- mark hashtags in SpaCy\n",
    "\n",
    "The user mentions are kept as one token. \n",
    "- mark them as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer\n",
    "Modify the tokenizer such that hashtags are not split at `#`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "import re\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n",
    "# overwrite token_match function of the tokenizer\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'gro√üe', 'Koalition', 'Merkel', '#GroKo', '#CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure the whitespaces are set correctly in between the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'gro√üe', 'Koalition', 'Merkel', '#GroKo', '#CDU', '#SPD']\n"
     ]
    }
   ],
   "source": [
    "def seperate_hashtags(text: str):\n",
    "    \"\"\"\n",
    "    Insert a whitespace if hashtags are missing a gap in between.  \n",
    "    \"\"\"\n",
    "    for i, j in enumerate(text):\n",
    "        if (text[i] == \"#\" and i > 0):\n",
    "            if text[i-1] != \" \":\n",
    "                    text = text[:i] + \" \" + text[i:]\n",
    "                    i+=1\n",
    "    return text\n",
    "\n",
    "QUERY = seperate_hashtags(QUERY)\n",
    "\n",
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Matcher\n",
    "Customize the Matcher to handle Tweet-specific syntax - i.e. hashtags.\n",
    "- Mark Hashtag (#)\n",
    "- Mark Twitter User (@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.user_matcher.UserMatcher at 0x7f07709a7160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hashtag_matcher import create_hashtag_matcher\n",
    "from src.user_matcher import create_user_matcher\n",
    "\n",
    "nlp.add_pipe(\"hashtag_matcher\") \n",
    "nlp.add_pipe(\"user_matcher\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_hashtag\n",
       "0    @amthor       False\n",
       "1      gro√üe       False\n",
       "2  Koalition       False\n",
       "3     Merkel       False\n",
       "4     #GroKo        True\n",
       "5       #CDU        True\n",
       "6       #SPD        True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_hashtag])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_user\n",
       "0    @amthor     True\n",
       "1      gro√üe    False\n",
       "2  Koalition    False\n",
       "3     Merkel    False\n",
       "4     #GroKo    False\n",
       "5       #CDU    False\n",
       "6       #SPD    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_user])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_user\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Named Entities\n",
    "How are named entities detected? Especially those that are hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NER Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>Named person or family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                NER Label\n",
       "0  Merkel  Named person or family."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    data.append([ent.text, spacy.explain(ent.label_)])\n",
    "    \n",
    "# displacy.render(doc, style=\"ent\")\n",
    "pd.DataFrame(data, columns=[\"Text\", \"NER Label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that named entities are treated not optimally. Sometimes named entities aren't detected or the corresponding tokens don't make sense. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>UPOS Tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactics</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha Token</th>\n",
       "      <th>Stop Token</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>@xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XxxXx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text UPOS Tag   Tag Syntactics   Shape  Alpha Token  Stop Token  \\\n",
       "0    @amthor    PROPN    NE       ROOT   @xxxx        False       False   \n",
       "1      gro√üe      ADJ  ADJA         nk    xxxx         True        True   \n",
       "2  Koalition     NOUN    NN       ROOT   Xxxxx         True       False   \n",
       "3     Merkel    PROPN    NE         nk   Xxxxx         True       False   \n",
       "4     #GroKo    PROPN    NE         nk  #XxxXx        False       False   \n",
       "5       #CDU    PROPN    NE       ROOT    #XXX        False       False   \n",
       "6       #SPD    PROPN    NE         nk    #XXX        False       False   \n",
       "\n",
       "   Hashtag   User  \n",
       "0    False   True  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4     True  False  \n",
       "5     True  False  \n",
       "6     True  False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append ([token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, token._.is_hashtag, token._.is_user])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Text\", \"UPOS Tag\", \"Tag\", \"Syntactics\", \"Shape\", \"Alpha Token\", \"Stop Token\", \"Hashtag\", \"User\"], index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Candidate Selection\n",
    "Extract terms that are used to find synonyms. The words to find synonyms for should be:\n",
    "- verbs or nouns\n",
    "- no hashtags or users\n",
    "- only alphabet characters\n",
    "- no e-mail, URLs or currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidate_terms(doc: spacy.tokens.doc.Doc, pos_tags):\n",
    "    \"\"\"\n",
    "    Select the tokens that should be used for finding similar terms.\n",
    "    \"\"\"\n",
    "    candidate_terms = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_tags:\n",
    "            continue\n",
    "\n",
    "        if token._.is_hashtag is True:\n",
    "            continue\n",
    "\n",
    "        if token._.is_user is True:\n",
    "            continue\n",
    "\n",
    "        if token.is_alpha is False:\n",
    "            continue\n",
    "\n",
    "        #if token.is_stop:\n",
    "        #    continue\n",
    "\n",
    "        if token.like_email:\n",
    "            continue\n",
    "\n",
    "        if token.like_url:\n",
    "            continue\n",
    "\n",
    "        if token.is_currency:\n",
    "            continue\n",
    "\n",
    "        # lemmatize token via ES query pattern\n",
    "        # token.lemma_\n",
    "\n",
    "        candidate_terms.append(token.text)\n",
    "    \n",
    "    return candidate_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gro√üe', 'Koalition', 'Merkel']\n"
     ]
    }
   ],
   "source": [
    "pos_tags = [\"VERB\", \"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "candidate_terms = select_candidate_terms(doc, pos_tags)\n",
    "\n",
    "print(candidate_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word Embeddings\n",
    "The following embeddings are applied to the selected terms\n",
    "- FastText\n",
    "- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of most similar words (synonyms) \n",
    "NUM_SIM_TERMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FastText model with **FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.load_model('data/fasttext/cc.de.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gro√üe': ['gr√∂√üere', 'grosse', 'riesengro√üe'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "ft_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "    synonyms = ft_model.get_nearest_neighbors(term, k=NUM_SIM_TERMS)\n",
    "    ft_synonyms[f\"{term}\"] = [n[1] for n in synonyms]\n",
    "    \n",
    "print(ft_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastText module gives pretty fancy results. Even out-of-vocabulary words are treated well as expected.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Word2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Word2Vec model via **Gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gensim_w2v_model = KeyedVectors.load_word2vec_format(fname=\"data/devmount/german.model\", no_header=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'gro√üe' does not appear in this model\n",
      "{'Koalition': ['Grosse_Koalition', 'Grossen_Koalition', 'Regierungskoalition'], 'Merkel': ['Kanzlerin_Merkel', 'Merkel_CDU', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "w2v_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "\n",
    "    if not gensim_w2v_model.has_index_for(term):\n",
    "        print(f\"The word '{term}' does not appear in this model\")\n",
    "\n",
    "    else:\n",
    "        synonyms = gensim_w2v_model.most_similar(term)[:NUM_SIM_TERMS]\n",
    "        w2v_synonyms[f\"{term}\"] = [n[0] for n in synonyms]\n",
    "\n",
    "\n",
    "print(w2v_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gensim_w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lemmatize the terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model seems to work properly. However, it is case-sensitive and may requires to lemmatize the terms. Otherwise the model can't find the correct word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Elastic Search\n",
    "\n",
    "Finally, the reformulated query is used to retrieve Tweets from the Elastic Search index."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Preparation\n",
    "Obtain a list of Hashtags, Twitter Users and Entities that are included in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#GroKo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#CDU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hashtag\n",
       "0  #GroKo\n",
       "1    #CDU\n",
       "2    #SPD"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = [t.text for t in doc if t._.is_hashtag ]\n",
    "\n",
    "pd.DataFrame(hashtags, columns=[\"Hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User\n",
       "0  @amthor"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = [t.text for t in doc if t._.is_user ]\n",
    "\n",
    "pd.DataFrame(users, columns=[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entity\n",
       "0  Merkel"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "pd.DataFrame(entities, columns=[\"Entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test purposes use a predefined list of synonyms\n",
    "ft_synonyms = {'gro√üe': ['gr√∂√üere', 'grosse', 'riesengro√üe'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Expansion Handling\n",
    "Now, it must be determined which of the terms of the initial query should be replaced or used to expand the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use co-occurences to find suitable terms\n",
    "\n",
    "ft_queries = []\n",
    "ft_queries.append([t for t in candidate_terms])\n",
    "\n",
    "for term in candidate_terms:\n",
    "    for synonym in ft_synonyms[term]:\n",
    "        ft_queries.append([synonym] + [t for t in candidate_terms if t != term])\n",
    "    \n",
    "ft_queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Query Formulation \n",
    "Finally, the resulting terms must be arranged in an Elastic Search query. Define a pattern to retrieve relevant tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from src.utils import es_connect\n",
    "\n",
    "import json\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('auth/es-credentials.ini')\n",
    "\n",
    "es_client = es_connect(credentials=config[\"ELASTIC\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a pattern for an Elastic Search query with\n",
    "- boolean operators (`AND`, `OR`)\n",
    "- boosting  `^`\n",
    "- filter\n",
    "\n",
    "The following Hyperparameters are set in order to modify the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the Elastic Search index \n",
    "INDEX = \"tweets_ngram\"\n",
    "\n",
    "# Number of tweets displayed as result\n",
    "SIZE = 10\n",
    "\n",
    "# Are retweets allowed?\n",
    "RETWEET = False\n",
    "\n",
    "# How much is the matching of hashtags boosted? \n",
    "HASHTAG_BOOST = None\n",
    "\n",
    "# Range of Tweets to be included (FROM, TO)\n",
    "TWEET_RANGE = (\"2021-01-01\", \"2023-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': '',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': ''}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-configured template for an elastic search query\n",
    "query = json.load(open('config/es-query.conf'))['query']\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set if retweets are allowed\n",
    "if RETWEET:\n",
    "    del query['bool']['must_not']['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for testing I use candidate terms which are not yet applied to word embeddings\n",
    "query['bool']['should']['query_string']['query'] = ' '.join(candidate_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the hashtags if present in initial user query\n",
    "if len(hashtags) > 0 :\n",
    "    query['bool']['must']['match']['hashtags'] = ' '.join([h[1:] for h in  hashtags])\n",
    "else:\n",
    "    del query['bool']['must']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HASHTAG_BOOST is not None:\n",
    "    query['bool']['should']['query_string'][\"fields\"][1] += f\"^{HASHTAG_BOOST}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "for entity in entities:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range for tweets\n",
    "query['bool']['filter'][0]['range']['created_at']['gte'] = TWEET_RANGE[0]\n",
    "query['bool']['filter'][1]['range']['created_at']['lte'] = TWEET_RANGE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'gro√üe Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': 'GroKo CDU SPD'}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': '2021-01-01'}}},\n",
       "   {'range': {'created_at': {'lte': '2023-01-01'}}}]}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Query\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the final Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 695 hits in 283ms \n",
      "\n",
      "Tweet 0 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'created_at': '2021-09-01T14:26:57+02:00', 'txt': 'S√§tze die formal korrekt sind aber halt auch Bekenntnisse.\\n\\n‚ÄúUnd wir [Wer? Politik? Boomer?] m√ºssen auch noch mehr [weil ihr das schon so viel tut?] mit der j√ºngeren Generation [weil nur die sich f√ºrs Klima interessiert ü§î] sprechen.‚Äù [zuh√∂ren! Ernst nehmen! Handel!]\\n#SPD #GroKo https://t.co/cA0tCDzFYA', 'hashtags': ['spd', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 1 \n",
      " {'retweet_count': 42, 'reply_count': 17, 'like_count': 350, 'created_at': '2021-08-29T15:25:10+02:00', 'txt': 'Von den letzten 16 Jahren hat die #SPD 12 Jahre mit der #CDU regiert. Die #SPD hat Scholz mit gro√üem Get√∂se nicht zum Parteivorsitzenden gew√§hlt,mit dem Argument,er st√ºnde f√ºr die #GroKo Jetzt ist er Kanzlerkandidat und kokettiert offen damit merkellike zu sein.Die Wahrheit ist:', 'hashtags': ['spd', 'spd', 'cdu', 'groko'], 'word_count': 44} \n",
      "\n",
      "Tweet 2 \n",
      " {'retweet_count': 13, 'reply_count': 3, 'like_count': 54, 'created_at': '2021-09-24T13:17:08+02:00', 'txt': 'Die BTW21 wird knapp. Meine drei Argumente f√ºr die #SPD: 1. die SPD hat klare Ziele: Mindestlohn, stabile Renten, co2-Neutrale Wirtschaft, 2.Die SPD hat den besseren Kanzlerkandidaten. 3. Die einmalig ideenlose und niedertr√§chtige Kampagne der #CDU darf nicht belohnt werden. https://t.co/mATcCTGbx3', 'hashtags': ['spd', 'cdu'], 'word_count': 41} \n",
      "\n",
      "Tweet 3 \n",
      " {'retweet_count': 0, 'reply_count': 1, 'like_count': 1, 'created_at': '2021-08-27T11:53:07+02:00', 'txt': '@HuebschenH Ja. Das ist wichtig:\\nEs gab eine ganz gro√üe Koalition aus #CDU, #FDP &amp; #SPD.\\nUnd eine SPD, die ab 2012 vor Kraft nicht laufen konnte, hat uns Gr√ºnen in der Koalition diesen Quatsch abgen√∂tigt.\\nWas lernen wir daraus:\\n#Gr√ºne st√§rker machen - mit 20% w√§re das nicht passiert!', 'hashtags': ['spd', 'cdu', 'fdp', 'gr√ºne'], 'word_count': 46} \n",
      "\n",
      "Tweet 4 \n",
      " {'retweet_count': 3, 'reply_count': 2, 'like_count': 89, 'created_at': '2021-09-02T17:20:59+02:00', 'txt': 'Mehr Klimaschutz, mehr soziale Gerechtigkeit, mehr au√üenpolitische Verantwortung - das alles gibt es mit unserer Kanzlerkandidatin @ABaerbock! Die Gesellschaft ist so viel weiter als die #GroKo. Es ist Zeit f√ºr den Gr√ºnen Wechsel - auch in #Bielefeld mit @BriHasselmann! https://t.co/uKbmHDKvEC', 'hashtags': ['groko', 'bielefeld'], 'word_count': 40} \n",
      "\n",
      "Tweet 5 \n",
      " {'retweet_count': 1, 'reply_count': 1, 'like_count': 2, 'created_at': '2021-10-03T22:33:39+02:00', 'txt': 'Die erste #GroKo in Deutschland vereinte 1966 noch 86,9% der W√§hler:innen hinter sich. Das l√§sst sich heute nicht mal mit einer Mosambik-Koalition erreichen. Aber wenn man #CDU und #FDP einerseits und #SPD und #Gr√ºne anderseits beobachtet, k√∂nnte man das glatt als L√∂sung sehen.', 'hashtags': ['spd', 'cdu', 'fdp', 'gr√ºne', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 6 \n",
      " {'retweet_count': 15, 'reply_count': 7, 'like_count': 126, 'created_at': '2021-08-21T13:37:47+02:00', 'txt': '‚ÄûEs ist inakzeptabel, dass bei #CDU und #SPD niemand Verantwortung √ºbernehmen will, f√ºr das Desaster ihrer Politik in #Afghanistan. Am dringlichsten ist jetzt, so viele Menschen zu retten, wie m√∂glich. Dann wird es um Aufkl√§rung gehen!‚Äú \\n\\nStarke Rede von @BriHasselmann #ldk21nrw https://t.co/Wf0yTyeVI6', 'hashtags': ['spd', 'cdu', 'afghanistan', 'ldk21nrw'], 'word_count': 42} \n",
      "\n",
      "Tweet 7 \n",
      " {'retweet_count': 91, 'reply_count': 39, 'like_count': 492, 'created_at': '2021-08-26T21:53:26+02:00', 'txt': '3‚Ç¨ mehr #HartzIV ab 2022. Das ist einfach frech! Dieses menschenunw√ºrdige HartzIV-Regime, das #SPD, #Gr√ºne, #CDU &amp; #FDP gro√ü gemacht haben, muss endlich enden. Artikel 1 des Grundgesetzes gilt f√ºr alle! Zeit f√ºr eine Mindestsicherung, die jeden vor Armut sch√ºtzt - sanktionsfrei!', 'hashtags': ['spd', 'hartziv', 'cdu', 'fdp', 'gr√ºne'], 'word_count': 42} \n",
      "\n",
      "Tweet 8 \n",
      " {'retweet_count': 2, 'reply_count': 2, 'like_count': 7, 'created_at': '2021-08-16T08:24:05+02:00', 'txt': '#Afghanistan Katastrophe mit Ansage. 20 Jahre die Dienste der Menschen dort in Anspruch genommen. Au√üenpolitik der #Bundesregierung =0. Holt alle Menschen in Not raus aus Afghanistan.  #Groko #SPD #CDU wiederholt nicht die Fehler aus Juni 21! @GrueneBundestag @JTrittin @KatjaKeul https://t.co/cG6XYpDYQR', 'hashtags': ['spd', 'cdu', 'afghanistan', 'bundesregierung', 'groko'], 'word_count': 41} \n",
      "\n",
      "Tweet 9 \n",
      " {'retweet_count': 8, 'reply_count': 4, 'like_count': 51, 'created_at': '2021-09-17T09:09:06+02:00', 'txt': 'F√ºr #Klima + #Wohlstand Gr√ºn w√§hlen üåª Wir erhalten und st√§rken unsere Freiheit u die kommender Generationen mit konsequentem Klimaschutz. Mit vorausschauender Politik, die die gro√üen Aufgaben anpackt statt einer #Groko, die erst handelt, wenn es zu sp√§t ist. #bereitweilihresseid https://t.co/kzHPldFquN', 'hashtags': ['bereitweilihresseid', 'klima', 'groko', 'wohlstand'], 'word_count': 41} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = es_client.search(index=INDEX, size=SIZE, query=query)\n",
    "\n",
    "print(f'Total of {res[\"hits\"][\"total\"][\"value\"]} hits in {res[\"took\"]}ms \\n')\n",
    "\n",
    "for i, doc in enumerate(res[\"hits\"][\"hits\"]):\n",
    "    print(\"Tweet\", i, \"\\n\", doc[\"_source\"], \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
