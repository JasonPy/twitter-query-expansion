{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Reformulation \n",
    "Step by step building a custom pipeline to handle queries for Twitter database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download one of the predefined German models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download german package\n",
    "MODEL = 'de_core_news_lg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load german language model\n",
    "nlp = spacy.load(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input a query for testing purposes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"@amthor die gro√üe Koalition Merkel #GroKo #CDU#SPD\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Tokens from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'die', 'gro√üe', 'Koalition', 'Merkel', '#', 'GroKo', '#', 'CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "print([token.text for token in doc])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preprocessing\n",
    "Hashtags are treated poorly. Detect them and prevent the tokenizer from splitting them.\n",
    "- don't split hashtag and it's text\n",
    "- split compound hashtags\n",
    "- mark hashtags in SpaCy\n",
    "\n",
    "The user mentions are kept as one token. \n",
    "- mark them as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer\n",
    "Modify the tokenizer such that hashtags are not split at `#`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "import re\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n",
    "# overwrite token_match function of the tokenizer\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'die', 'gro√üe', 'Koalition', 'Merkel', '#GroKo', '#CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure the whitespaces are set correctly in between the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'die', 'gro√üe', 'Koalition', 'Merkel', '#GroKo', '#CDU', '#SPD']\n"
     ]
    }
   ],
   "source": [
    "def seperate_hashtags(text: str):\n",
    "    \"\"\"\n",
    "    Insert a whitespace if hashtags are missing a gap in between.  \n",
    "    \"\"\"\n",
    "    for i, j in enumerate(text):\n",
    "        if (text[i] == \"#\" and i > 0):\n",
    "            if text[i-1] != \" \":\n",
    "                    text = text[:i] + \" \" + text[i:]\n",
    "                    i+=1\n",
    "    return text\n",
    "\n",
    "QUERY = seperate_hashtags(QUERY)\n",
    "\n",
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Matcher\n",
    "Customize the Matcher to handle Tweet-specific syntax - i.e. hashtags.\n",
    "- Mark Hashtag (#)\n",
    "- Mark Twitter User (@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.user_matcher.UserMatcher at 0x7fd3b01662c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hashtag_matcher import create_hashtag_matcher\n",
    "from src.user_matcher import create_user_matcher\n",
    "\n",
    "nlp.add_pipe(\"hashtag_matcher\") \n",
    "nlp.add_pipe(\"user_matcher\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_hashtag\n",
       "0    @amthor       False\n",
       "1        die       False\n",
       "2      gro√üe       False\n",
       "3  Koalition       False\n",
       "4     Merkel       False\n",
       "5     #GroKo        True\n",
       "6       #CDU        True\n",
       "7       #SPD        True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_hashtag])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_user\n",
       "0    @amthor     True\n",
       "1        die    False\n",
       "2      gro√üe    False\n",
       "3  Koalition    False\n",
       "4     Merkel    False\n",
       "5     #GroKo    False\n",
       "6       #CDU    False\n",
       "7       #SPD    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_user])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_user\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Named Entities\n",
    "How are named entities detected? Especially those that are hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NER Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>Named person or family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                NER Label\n",
       "0  Merkel  Named person or family."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    data.append([ent.text, spacy.explain(ent.label_)])\n",
    "    \n",
    "# displacy.render(doc, style=\"ent\")\n",
    "pd.DataFrame(data, columns=[\"Text\", \"NER Label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that named entities are treated not optimally. Sometimes named entities aren't detected or the corresponding tokens don't make sense. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>UPOS Tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactics</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha Token</th>\n",
       "      <th>Stop Token</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>@xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>die</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gro√üe</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>oa</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XxxXx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text UPOS Tag   Tag Syntactics   Shape  Alpha Token  Stop Token  \\\n",
       "0    @amthor     NOUN    NE       ROOT   @xxxx        False       False   \n",
       "1        die      DET   ART         nk     xxx         True        True   \n",
       "2      gro√üe      ADJ  ADJA         nk    xxxx         True        True   \n",
       "3  Koalition     NOUN    NN         oa   Xxxxx         True       False   \n",
       "4     Merkel    PROPN    NE         nk   Xxxxx         True       False   \n",
       "5     #GroKo    PROPN    NE         nk  #XxxXx        False       False   \n",
       "6       #CDU    PROPN    NE       ROOT    #XXX        False       False   \n",
       "7       #SPD    PROPN    NE         nk    #XXX        False       False   \n",
       "\n",
       "   Hashtag   User  \n",
       "0    False   True  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4    False  False  \n",
       "5     True  False  \n",
       "6     True  False  \n",
       "7     True  False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append ([token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, token._.is_hashtag, token._.is_user])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Text\", \"UPOS Tag\", \"Tag\", \"Syntactics\", \"Shape\", \"Alpha Token\", \"Stop Token\", \"Hashtag\", \"User\"], index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Candidate Selection\n",
    "Extract terms that are used to find synonyms. The words to find synonyms for should be:\n",
    "- verbs or nouns\n",
    "- no hashtags or users\n",
    "- only alphabet characters\n",
    "- no e-mail, URLs or currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidate_terms(doc: spacy.tokens.doc.Doc, pos_tags):\n",
    "    \"\"\"\n",
    "    Select the tokens that should be used for finding synonyms.\n",
    "    \"\"\"\n",
    "    candidate_terms = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_tags:\n",
    "            continue\n",
    "\n",
    "        if token._.is_hashtag is True:\n",
    "            continue\n",
    "\n",
    "        if token._.is_user is True:\n",
    "            continue\n",
    "\n",
    "        if token.is_alpha is False:\n",
    "            continue\n",
    "\n",
    "        #if token.is_stop:\n",
    "        #    continue\n",
    "\n",
    "        if token.like_email:\n",
    "            continue\n",
    "\n",
    "        if token.like_url:\n",
    "            continue\n",
    "\n",
    "        if token.is_currency:\n",
    "            continue\n",
    "\n",
    "        # lemmatize token at the end? or via ES (THIS IS FOR EMBEDDINGS)\n",
    "        # token.lemma_\n",
    "\n",
    "        candidate_terms.append(token.text)\n",
    "    \n",
    "    return candidate_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gro√üe', 'Koalition', 'Merkel']\n"
     ]
    }
   ],
   "source": [
    "pos_tags = [\"VERB\", \"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "candidate_terms = select_candidate_terms(doc, pos_tags)\n",
    "\n",
    "print(candidate_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word Embeddings\n",
    "The following embeddings are applied to the selected terms\n",
    "- FastText\n",
    "- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of most similar words (synonyms) \n",
    "NUM_SIM_TERMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load FastText model with **SpaCy**\n",
    "If a large german pipeline is loaded, word vectors are already available. Otherwise, a model can be loaded manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the German FastText model run the following command\n",
    "# !python -m spacy init vectors de ../data/fasttext/cc.de.300.zip ../models/de-fasttext-10000 --prune 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ft = spacy.load(\"../models/de-fasttext-10000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haus | Katze -> 0.367066624402335\n",
      "Katze | Hund -> 0.7219703586509103\n",
      "Haus | Bude -> 0.6441379922375441\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp_ft(\"Haus\")\n",
    "doc2 = nlp_ft(\"Katze\")\n",
    "doc3 = nlp_ft(\"Hund\")\n",
    "doc4 = nlp_ft(\"Bude\")\n",
    "\n",
    "print(f\"Haus | Katze -> {doc1.similarity(doc2)}\")\n",
    "print(f\"Katze | Hund -> {doc2.similarity(doc3)}\")\n",
    "print(f\"Haus | Bude -> {doc1.similarity(doc4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to free up space afterwards\n",
    "del nlp_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since SpaCy does not support finding similar terms given a term - I refer to Gensim and FastText to load the word vectors there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load FastText model with **Gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_vectors, load_facebook_model\n",
    "\n",
    "# model too big to load\n",
    "gensim_ft_model = load_facebook_vectors(\"../data/fasttext/cc.de.300.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find most similar terms for a given term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merkels', 0.7103838920593262),\n",
       " ('gauck', 0.6791979670524597),\n",
       " ('sch√§uble', 0.6752827167510986),\n",
       " ('Merkel', 0.6560235023498535),\n",
       " ('kanzlerin', 0.6355306506156921),\n",
       " ('bundeskanzlerin', 0.626380980014801),\n",
       " ('westerwelle', 0.6188872456550598),\n",
       " ('steinbr√ºck', 0.6188532710075378),\n",
       " ('cdu', 0.6108233332633972),\n",
       " ('steinmeier', 0.6054732203483582)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_ft_model.most_similar(\"merkel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gensim_ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a FastText model via Gensim takes an eternity. Also, out-of-vocabulary words aren't handled.\n",
    "Thus, this approach is neglected and referred to the FastText python module of Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Load FastText model with **FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.load_model('../data/fasttext/cc.de.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gro√üe': ['gr√∂√üere', 'grosse', 'riesengro√üe'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "ft_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "    synonyms = ft_model.get_nearest_neighbors(term.text, k=NUM_SIM_TERMS)\n",
    "    ft_synonyms[f\"{term.text}\"] = [n[1] for n in synonyms]\n",
    "    \n",
    "print(ft_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastText module gives pretty fancy results. Even out-of-vocabulary words are treated well as expected.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Word2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Word2Vec model via **Gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gensim_w2v_model = KeyedVectors.load_word2vec_format(fname=\"../data/devmount/german.model\", no_header=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'gro√üe' does not appear in this model\n",
      "{'Koalition': ['Grosse_Koalition', 'Grossen_Koalition', 'Regierungskoalition'], 'Merkel': ['Kanzlerin_Merkel', 'Merkel_CDU', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "w2v_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "\n",
    "    if not gensim_w2v_model.has_index_for(term.text):\n",
    "        print(f\"The word '{term.text}' does not appear in this model\")\n",
    "\n",
    "    else:\n",
    "        synonyms = gensim_w2v_model.most_similar(term.text)[:NUM_SIM_TERMS]\n",
    "        w2v_synonyms[f\"{term.text}\"] = [n[0] for n in synonyms]\n",
    "\n",
    "\n",
    "print(w2v_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gensim_w2v_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model seems to work properly. However, it is case-sensitive and may requires to lemmatize the terms. Otherwise the model can't find the correct word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Elastic Search\n",
    "\n",
    "Finally, the reformulated query is used to retrieve Tweets from the Elastic Search index."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Preparation\n",
    "Obtain a list of Hashtags, Twitter Users and Entities that are included in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#GroKo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#CDU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hashtag\n",
       "0  #GroKo\n",
       "1    #CDU\n",
       "2    #SPD"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = [t.text for t in doc if t._.is_hashtag ]\n",
    "\n",
    "pd.DataFrame(hashtags, columns=[\"Hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User\n",
       "0  @amthor"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = [t.text for t in doc if t._.is_user ]\n",
    "\n",
    "pd.DataFrame(users, columns=[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entity\n",
       "0  Merkel"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "pd.DataFrame(entities, columns=[\"Entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test purposes use a predefined list of synonyms\n",
    "ft_synonyms = {'gro√üe': ['gr√∂√üere', 'grosse', 'riesengro√üe'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Term Replacement\n",
    "Now, it must be determined which of the terms of the initial query should be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_queries = []\n",
    "ft_queries.append([t.text for t in candidate_terms])\n",
    "\n",
    "for term in candidate_terms:\n",
    "    for synonym in ft_synonyms[term.text]:\n",
    "        ft_queries.append([synonym] + [t.text for t in candidate_terms if t.text != term.text])\n",
    "    \n",
    "ft_queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Query Formulation \n",
    "Finally, the resulting terms must be arranged in an Elastic Search query. Define a pattern to retrieve relevant tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from src.utils import es_connect\n",
    "\n",
    "import json\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('auth/es-credentials.ini')\n",
    "\n",
    "es_client = es_connect(credentials=config[\"ELASTIC\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a pattern for an Elastic Search query with\n",
    "- boolean operators (`AND`, `OR`)\n",
    "- boosting  `^`\n",
    "- filter\n",
    "\n",
    "The following Hyperparameters are set in order to modify the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the Elastic Search index \n",
    "INDEX = \"tweets_aa\"\n",
    "\n",
    "# Number of tweets displayed as result\n",
    "SIZE = 10\n",
    "\n",
    "# Are retweets allowed?\n",
    "RETWEET = False\n",
    "\n",
    "# How much is the matching of hashtags boosted? \n",
    "HASHTAG_BOOST = None\n",
    "\n",
    "# Range of Tweets to be included (FROM, TO)\n",
    "TWEET_RANGE = (\"2021-01-01\", \"2023-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': '',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': ''}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-configured template for an elastic search query\n",
    "query = json.load(open('config/es-query.conf'))['query']\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': '',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': ''}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set if retweets are allowed\n",
    "if RETWEET:\n",
    "    del query['bool']['must_not']['term']\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'gro√üe Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': ''}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: for testing I use candidate terms which are not yet applied to word embeddings\n",
    "query['bool']['should']['query_string']['query'] = ' '.join(candidate_terms)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'gro√üe Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': 'GroKo CDU SPD'}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert the hashtags if present in initial user query\n",
    "if len(hashtags) > 0 :\n",
    "    query['bool']['must']['match']['hashtags'] = ' '.join([h[1:] for h in  hashtags])\n",
    "else:\n",
    "    del query['bool']['must']\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'gro√üe Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': 'GroKo CDU SPD'}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if HASHTAG_BOOST is not None:\n",
    "    query['bool']['should']['query_string'][\"fields\"][1] += f\"^{HASHTAG_BOOST}\"\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "for entity in entities:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'gro√üe Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': 'GroKo CDU SPD'}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': '2021-01-01'}}},\n",
       "   {'range': {'created_at': {'lte': '2023-01-01'}}}]}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set date range for tweets\n",
    "query['bool']['filter'][0]['range']['created_at']['gte'] = TWEET_RANGE[0]\n",
    "query['bool']['filter'][1]['range']['created_at']['lte'] = TWEET_RANGE[1]\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the final Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 1676 hits in 5ms \n",
      "\n",
      "Tweet 0 \n",
      " {'retweet_count': 42, 'reply_count': 17, 'like_count': 350, 'created_at': '2021-08-29T15:25:10+02:00', 'txt': 'Von den letzten 16 Jahren hat die #SPD 12 Jahre mit der #CDU regiert. Die #SPD hat Scholz mit gro√üem Get√∂se nicht zum Parteivorsitzenden gew√§hlt,mit dem Argument,er st√ºnde f√ºr die #GroKo Jetzt ist er Kanzlerkandidat und kokettiert offen damit merkellike zu sein.Die Wahrheit ist:', 'hashtags': ['spd', 'spd', 'cdu', 'groko'], 'word_count': 44} \n",
      "\n",
      "Tweet 1 \n",
      " {'retweet_count': 3, 'reply_count': 12, 'like_count': 62, 'created_at': '2021-08-04T21:08:27+02:00', 'txt': 'Die #SPD pr√§sentiert im Werbespot ihre Erfolge der 12 Jahre gemeinsamer Regierungsarbeit mit der #CDU unter Angela #Merkel. Sex vor der Ehe f√ºr sich pers√∂nlich abzulehnen ist f√ºr die @spdde schon Verhetzungsgrund. Da muss bei @OlafScholz ja die Panik gro√ü sein. Fair geht anders. https://t.co/tMrtgXgpSY', 'hashtags': ['spd', 'cdu', 'merkel'], 'word_count': 45} \n",
      "\n",
      "Tweet 2 \n",
      " {'retweet_count': 9, 'reply_count': 27, 'like_count': 134, 'created_at': '2021-08-30T12:11:23+02:00', 'txt': 'Ob die Hilfe von Frau #Merkel, Armin #Laschet so viel helfen w√ºrde? ü§î\\nüëâWenn nach 16 Jahren in der Regierung die #CDU in Umfragen schw√§cher dasteht, als die #SPD, dann ist die Bundeskanzlerin vielleicht keine ganz so gro√üe Hilfe.ü§∑\\u200d‚ôÇÔ∏è https://t.co/udeyvskSFS', 'hashtags': ['spd', 'laschet', 'cdu', 'merkel'], 'word_count': 39} \n",
      "\n",
      "Tweet 3 \n",
      " {'retweet_count': 1, 'reply_count': 1, 'like_count': 2, 'created_at': '2021-10-03T22:33:39+02:00', 'txt': 'Die erste #GroKo in Deutschland vereinte 1966 noch 86,9% der W√§hler:innen hinter sich. Das l√§sst sich heute nicht mal mit einer Mosambik-Koalition erreichen. Aber wenn man #CDU und #FDP einerseits und #SPD und #Gr√ºne anderseits beobachtet, k√∂nnte man das glatt als L√∂sung sehen.', 'hashtags': ['spd', 'cdu', 'fdp', 'gr√ºne', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 4 \n",
      " {'retweet_count': 0, 'reply_count': 1, 'like_count': 1, 'created_at': '2021-08-27T11:53:07+02:00', 'txt': '@HuebschenH Ja. Das ist wichtig:\\nEs gab eine ganz gro√üe Koalition aus #CDU, #FDP &amp; #SPD.\\nUnd eine SPD, die ab 2012 vor Kraft nicht laufen konnte, hat uns Gr√ºnen in der Koalition diesen Quatsch abgen√∂tigt.\\nWas lernen wir daraus:\\n#Gr√ºne st√§rker machen - mit 20% w√§re das nicht passiert!', 'hashtags': ['spd', 'cdu', 'fdp', 'gr√ºne'], 'word_count': 46} \n",
      "\n",
      "Tweet 5 \n",
      " {'retweet_count': 5, 'reply_count': 0, 'like_count': 42, 'created_at': '2021-08-31T14:10:41+02:00', 'txt': 'Dass #CDU &amp; #SPD im Wahlkampf nach wie vor eher Angst vor dem Gegner oder m√∂glichen Koalitionen sch√ºren &amp; Personenbashing betreiben, liegt entweder daran, dass man extrem verzweifelt ist oder dass einfach keine Inhalte da sind. Im Zweifel trifft beides zu.', 'hashtags': ['spd', 'cdu'], 'word_count': 41} \n",
      "\n",
      "Tweet 6 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 3, 'created_at': '2021-10-09T11:34:54+02:00', 'txt': 'Gr√ºne u rote Jugend wissen was sie wollen. Eine üö•-Koalition oder eine Bundesregierung, die gemeinsam gestaltet, geh√∂ren wohl nicht dazu. Ach, bleibt doch bei der #Groko, dann k√∂nnt ihr weiter nach Herzenslust gegen was auch immer protestieren.', 'hashtags': ['groko'], 'word_count': 37} \n",
      "\n",
      "Tweet 7 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 13, 'created_at': '2021-09-04T12:24:23+02:00', 'txt': 'Eine gute Nachricht f√ºr #SachsenAnhalt. Gratulation an die @SPD_LSA. Die Mehrheit der Menschen in unserem Bundesland w√ºnscht sich eine #Koalition aus #CDU, #SPD &amp; #FDP. Auf dem Weg zur #Deutschland-Koalition sind wir heute einen gro√üen Schritt weiter gegangen. @cdulsa @FDP_LSA https://t.co/gP87TbnXsZ', 'hashtags': ['spd', 'cdu', 'deutschland', 'fdp', 'sachsenanhalt', 'koalition'], 'word_count': 41} \n",
      "\n",
      "Tweet 8 \n",
      " {'retweet_count': 28, 'reply_count': 7, 'like_count': 191, 'created_at': '2021-09-02T20:44:54+02:00', 'txt': 'Das Versagen der #GroKo #cdu #spd in einem Tweet \\nüëéüèºParteitaktik √ºber alles \\nüëéüèºin 4 J. keine wirkliche Reform hinbekommen\\nüëéüèº Oppositionsvorschl. wie immer abgelehnt \\n\\nüëéüèºüëéüèº Konsequenz: evtl √ºber 900 MdB inkl. riesiger Kosten &amp; Chaos https://t.co/K9s1T8dVH5', 'hashtags': ['spd', 'cdu', 'groko'], 'word_count': 35} \n",
      "\n",
      "Tweet 9 \n",
      " {'retweet_count': 21, 'reply_count': 12, 'like_count': 94, 'created_at': '2021-09-01T18:06:18+02:00', 'txt': 'Es ist so: Wenn es eine Mehrheit f√ºr eine Neuauflage einer #GroKo gibt (diesmal vielleicht mit der #SPD im BKanzAmt), ist die Wahrscheinlichkeit sehr hoch, dass sie kommt. SPD und #CDU sind sich in vielen Fragen sehr √§hnlich. https://t.co/KzjdtU0zjd https://t.co/nQhoZIqa6J', 'hashtags': ['spd', 'cdu', 'groko'], 'word_count': 40} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = es_client.search(index=INDEX, size=SIZE, query=query)\n",
    "\n",
    "print(f'Total of {res[\"hits\"][\"total\"][\"value\"]} hits in {res[\"took\"]}ms \\n')\n",
    "\n",
    "for i, doc in enumerate(res[\"hits\"][\"hits\"]):\n",
    "    print(\"Tweet\", i, \"\\n\", doc[\"_source\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
