{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Reformulation \n",
    "Step by step building a custom pipeline to handle queries for Twitter database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download one of the predefined German models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download de_core_news_sm\n",
    "# !python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select german package\n",
    "MODEL = 'de_core_news_lg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load german language model\n",
    "nlp = spacy.load(MODEL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a user query to test the whole pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = \"@amthor große Koalition Merkel #GroKo #CDU#SPD\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate Tokens from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'große', 'Koalition', 'Merkel', '#', 'GroKo', '#', 'CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True)\n",
    "print([token.text for token in doc])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preprocessing\n",
    "Hashtags are treated poorly. Detect them and prevent the tokenizer from splitting them.\n",
    "- don't split hashtag and it's text\n",
    "- split compound hashtags\n",
    "- mark hashtags in SpaCy\n",
    "\n",
    "The user mentions are kept as one token. \n",
    "- mark them as well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Tokenizer\n",
    "Modify the tokenizer such that hashtags are not split at `#`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import _get_regex_pattern\n",
    "import re\n",
    "\n",
    "# get default pattern for tokens that don't get split\n",
    "re_token_match = _get_regex_pattern(nlp.Defaults.token_match)\n",
    "\n",
    "# add your patterns (here: hashtags and in-word hyphens)\n",
    "re_token_match = f\"({re_token_match}|#\\w+|\\w+-\\w+)\"\n",
    "\n",
    "# overwrite token_match function of the tokenizer\n",
    "nlp.tokenizer.token_match = re.compile(re_token_match).match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'große', 'Koalition', 'Merkel', '#GroKo', '#CDU#SPD']\n"
     ]
    }
   ],
   "source": [
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure the whitespaces are set correctly in between the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@amthor', 'große', 'Koalition', 'Merkel', '#GroKo', '#CDU', '#SPD']\n"
     ]
    }
   ],
   "source": [
    "def seperate_hashtags(text: str):\n",
    "    \"\"\"\n",
    "    Insert a whitespace if hashtags are missing a gap in between.  \n",
    "    \"\"\"\n",
    "    for i, j in enumerate(text):\n",
    "        if (text[i] == \"#\" and i > 0):\n",
    "            if text[i-1] != \" \":\n",
    "                    text = text[:i] + \" \" + text[i:]\n",
    "                    i+=1\n",
    "    return text\n",
    "\n",
    "QUERY = seperate_hashtags(QUERY)\n",
    "\n",
    "print([token.text for token in nlp(QUERY)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Matcher\n",
    "Customize the Matcher to handle Tweet-specific syntax - i.e. hashtags.\n",
    "- Mark Hashtag (#)\n",
    "- Mark Twitter User (@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.user_matcher.UserMatcher at 0x7f07709a7160>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hashtag_matcher import create_hashtag_matcher\n",
    "from src.user_matcher import create_user_matcher\n",
    "\n",
    "nlp.add_pipe(\"hashtag_matcher\") \n",
    "nlp.add_pipe(\"user_matcher\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>große</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_hashtag\n",
       "0    @amthor       False\n",
       "1      große       False\n",
       "2  Koalition       False\n",
       "3     Merkel       False\n",
       "4     #GroKo        True\n",
       "5       #CDU        True\n",
       "6       #SPD        True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_hashtag])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>is_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>große</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text  is_user\n",
       "0    @amthor     True\n",
       "1      große    False\n",
       "2  Koalition    False\n",
       "3     Merkel    False\n",
       "4     #GroKo    False\n",
       "5       #CDU    False\n",
       "6       #SPD    False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append([token, token._.is_user])\n",
    "pd.DataFrame(data, columns=[\"Text\", \"is_user\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Named Entities\n",
    "How are named entities detected? Especially those that are hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NER Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>Named person or family.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Text                NER Label\n",
       "0  Merkel  Named person or family."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(QUERY)\n",
    "data = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    data.append([ent.text, spacy.explain(ent.label_)])\n",
    "    \n",
    "# displacy.render(doc, style=\"ent\")\n",
    "pd.DataFrame(data, columns=[\"Text\", \"NER Label\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that named entities are treated not optimally. Sometimes named entities aren't detected or the corresponding tokens don't make sense. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.4 Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>UPOS Tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactics</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha Token</th>\n",
       "      <th>Stop Token</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>@xxxx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>große</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJA</td>\n",
       "      <td>nk</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Koalition</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merkel</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#GroKo</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XxxXx</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#CDU</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#SPD</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NE</td>\n",
       "      <td>nk</td>\n",
       "      <td>#XXX</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Text UPOS Tag   Tag Syntactics   Shape  Alpha Token  Stop Token  \\\n",
       "0    @amthor    PROPN    NE       ROOT   @xxxx        False       False   \n",
       "1      große      ADJ  ADJA         nk    xxxx         True        True   \n",
       "2  Koalition     NOUN    NN       ROOT   Xxxxx         True       False   \n",
       "3     Merkel    PROPN    NE         nk   Xxxxx         True       False   \n",
       "4     #GroKo    PROPN    NE         nk  #XxxXx        False       False   \n",
       "5       #CDU    PROPN    NE       ROOT    #XXX        False       False   \n",
       "6       #SPD    PROPN    NE         nk    #XXX        False       False   \n",
       "\n",
       "   Hashtag   User  \n",
       "0    False   True  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4     True  False  \n",
       "5     True  False  \n",
       "6     True  False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for token in doc:\n",
    "    data.append ([token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, token._.is_hashtag, token._.is_user])\n",
    "\n",
    "pd.DataFrame(data, columns=[\"Text\", \"UPOS Tag\", \"Tag\", \"Syntactics\", \"Shape\", \"Alpha Token\", \"Stop Token\", \"Hashtag\", \"User\"], index=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.5 Candidate Selection\n",
    "Extract terms that are used to find synonyms. The words to find synonyms for should be:\n",
    "- verbs or nouns\n",
    "- no hashtags or users\n",
    "- only alphabet characters\n",
    "- no e-mail, URLs or currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_candidate_terms(doc: spacy.tokens.doc.Doc, pos_tags):\n",
    "    \"\"\"\n",
    "    Select the tokens that should be used for finding similar terms.\n",
    "    \"\"\"\n",
    "    candidate_terms = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.pos_ not in pos_tags:\n",
    "            continue\n",
    "\n",
    "        if token._.is_hashtag is True:\n",
    "            continue\n",
    "\n",
    "        if token._.is_user is True:\n",
    "            continue\n",
    "\n",
    "        if token.is_alpha is False:\n",
    "            continue\n",
    "\n",
    "        #if token.is_stop:\n",
    "        #    continue\n",
    "\n",
    "        if token.like_email:\n",
    "            continue\n",
    "\n",
    "        if token.like_url:\n",
    "            continue\n",
    "\n",
    "        if token.is_currency:\n",
    "            continue\n",
    "\n",
    "        # lemmatize token via ES query pattern\n",
    "        # token.lemma_\n",
    "\n",
    "        candidate_terms.append(token.text)\n",
    "    \n",
    "    return candidate_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['große', 'Koalition', 'Merkel']\n"
     ]
    }
   ],
   "source": [
    "pos_tags = [\"VERB\", \"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "candidate_terms = select_candidate_terms(doc, pos_tags)\n",
    "\n",
    "print(candidate_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word Embeddings\n",
    "The following embeddings are applied to the selected terms\n",
    "- FastText\n",
    "- Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of most similar words (synonyms) \n",
    "NUM_SIM_TERMS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 FastText"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load FastText model with **FastText**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "\n",
    "ft_model = fasttext.load_model('data/fasttext/cc.de.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'große': ['größere', 'grosse', 'riesengroße'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "ft_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "    synonyms = ft_model.get_nearest_neighbors(term, k=NUM_SIM_TERMS)\n",
    "    ft_synonyms[f\"{term}\"] = [n[1] for n in synonyms]\n",
    "    \n",
    "print(ft_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FastText module gives pretty fancy results. Even out-of-vocabulary words are treated well as expected.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2 Word2Vec\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Word2Vec model via **Gensim**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "gensim_w2v_model = KeyedVectors.load_word2vec_format(fname=\"data/devmount/german.model\", no_header=False, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'große' does not appear in this model\n",
      "{'Koalition': ['Grosse_Koalition', 'Grossen_Koalition', 'Regierungskoalition'], 'Merkel': ['Kanzlerin_Merkel', 'Merkel_CDU', 'Bundeskanzlerin']}\n"
     ]
    }
   ],
   "source": [
    "w2v_synonyms = {}\n",
    "\n",
    "for term in candidate_terms:\n",
    "\n",
    "    if not gensim_w2v_model.has_index_for(term):\n",
    "        print(f\"The word '{term}' does not appear in this model\")\n",
    "\n",
    "    else:\n",
    "        synonyms = gensim_w2v_model.most_similar(term)[:NUM_SIM_TERMS]\n",
    "        w2v_synonyms[f\"{term}\"] = [n[0] for n in synonyms]\n",
    "\n",
    "\n",
    "print(w2v_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del gensim_w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: lemmatize the terms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model seems to work properly. However, it is case-sensitive and may requires to lemmatize the terms. Otherwise the model can't find the correct word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Elastic Search\n",
    "\n",
    "Finally, the reformulated query is used to retrieve Tweets from the Elastic Search index."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Preparation\n",
    "Obtain a list of Hashtags, Twitter Users and Entities that are included in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#GroKo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#CDU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hashtag\n",
       "0  #GroKo\n",
       "1    #CDU\n",
       "2    #SPD"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags = [t.text for t in doc if t._.is_hashtag ]\n",
    "\n",
    "pd.DataFrame(hashtags, columns=[\"Hashtag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@amthor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User\n",
       "0  @amthor"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = [t.text for t in doc if t._.is_user ]\n",
    "\n",
    "pd.DataFrame(users, columns=[\"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merkel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Entity\n",
       "0  Merkel"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = [ent.text for ent in doc.ents]\n",
    "\n",
    "pd.DataFrame(entities, columns=[\"Entity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test purposes use a predefined list of synonyms\n",
    "ft_synonyms = {'große': ['größere', 'grosse', 'riesengroße'], 'Koalition': ['Regierungskoalition', 'Koalitionsrunde', 'Koalitionspartei'], 'Merkel': ['Kanzlerin', 'Merkels', 'Bundeskanzlerin']}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.2 Expansion Handling\n",
    "Now, it must be determined which of the terms of the initial query should be replaced or used to expand the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use co-occurences to find suitable terms\n",
    "\n",
    "ft_queries = []\n",
    "ft_queries.append([t for t in candidate_terms])\n",
    "\n",
    "for term in candidate_terms:\n",
    "    for synonym in ft_synonyms[term]:\n",
    "        ft_queries.append([synonym] + [t for t in candidate_terms if t != term])\n",
    "    \n",
    "ft_queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3.3 Query Formulation \n",
    "Finally, the resulting terms must be arranged in an Elastic Search query. Define a pattern to retrieve relevant tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "from src.utils import es_connect\n",
    "\n",
    "import json\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('auth/es-credentials.ini')\n",
    "\n",
    "es_client = es_connect(credentials=config[\"ELASTIC\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a pattern for an Elastic Search query with\n",
    "- boolean operators (`AND`, `OR`)\n",
    "- boosting  `^`\n",
    "- filter\n",
    "\n",
    "The following Hyperparameters are set in order to modify the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the Elastic Search index \n",
    "INDEX = \"tweets_ngram\"\n",
    "\n",
    "# Number of tweets displayed as result\n",
    "SIZE = 10\n",
    "\n",
    "# Are retweets allowed?\n",
    "RETWEET = False\n",
    "\n",
    "# How much is the matching of hashtags boosted? \n",
    "HASHTAG_BOOST = None\n",
    "\n",
    "# Range of Tweets to be included (FROM, TO)\n",
    "TWEET_RANGE = (\"2021-01-01\", \"2023-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': '',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': ''}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': ''}}},\n",
       "   {'range': {'created_at': {'lte': ''}}}]}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-configured template for an elastic search query\n",
    "query = json.load(open('config/es-query.conf'))['query']\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulate Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set if retweets are allowed\n",
    "if RETWEET:\n",
    "    del query['bool']['must_not']['term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: for testing I use candidate terms which are not yet applied to word embeddings\n",
    "query['bool']['should']['query_string']['query'] = ' '.join(candidate_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the hashtags if present in initial user query\n",
    "if len(hashtags) > 0 :\n",
    "    query['bool']['must']['match']['hashtags'] = ' '.join([h[1:] for h in  hashtags])\n",
    "else:\n",
    "    del query['bool']['must']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HASHTAG_BOOST is not None:\n",
    "    query['bool']['should']['query_string'][\"fields\"][1] += f\"^{HASHTAG_BOOST}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "for entity in entities:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set date range for tweets\n",
    "query['bool']['filter'][0]['range']['created_at']['gte'] = TWEET_RANGE[0]\n",
    "query['bool']['filter'][1]['range']['created_at']['lte'] = TWEET_RANGE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bool': {'should': {'query_string': {'query': 'große Koalition Merkel',\n",
       "    'fields': ['txt', 'hashtags']}},\n",
       "  'must': {'match': {'hashtags': 'GroKo CDU SPD'}},\n",
       "  'must_not': {'term': {'txt': '_retweet_'}},\n",
       "  'filter': [{'range': {'created_at': {'gte': '2021-01-01'}}},\n",
       "   {'range': {'created_at': {'lte': '2023-01-01'}}}]}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Query\n",
    "query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the final Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 695 hits in 283ms \n",
      "\n",
      "Tweet 0 \n",
      " {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'created_at': '2021-09-01T14:26:57+02:00', 'txt': 'Sätze die formal korrekt sind aber halt auch Bekenntnisse.\\n\\n“Und wir [Wer? Politik? Boomer?] müssen auch noch mehr [weil ihr das schon so viel tut?] mit der jüngeren Generation [weil nur die sich fürs Klima interessiert 🤔] sprechen.” [zuhören! Ernst nehmen! Handel!]\\n#SPD #GroKo https://t.co/cA0tCDzFYA', 'hashtags': ['spd', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 1 \n",
      " {'retweet_count': 42, 'reply_count': 17, 'like_count': 350, 'created_at': '2021-08-29T15:25:10+02:00', 'txt': 'Von den letzten 16 Jahren hat die #SPD 12 Jahre mit der #CDU regiert. Die #SPD hat Scholz mit großem Getöse nicht zum Parteivorsitzenden gewählt,mit dem Argument,er stünde für die #GroKo Jetzt ist er Kanzlerkandidat und kokettiert offen damit merkellike zu sein.Die Wahrheit ist:', 'hashtags': ['spd', 'spd', 'cdu', 'groko'], 'word_count': 44} \n",
      "\n",
      "Tweet 2 \n",
      " {'retweet_count': 13, 'reply_count': 3, 'like_count': 54, 'created_at': '2021-09-24T13:17:08+02:00', 'txt': 'Die BTW21 wird knapp. Meine drei Argumente für die #SPD: 1. die SPD hat klare Ziele: Mindestlohn, stabile Renten, co2-Neutrale Wirtschaft, 2.Die SPD hat den besseren Kanzlerkandidaten. 3. Die einmalig ideenlose und niederträchtige Kampagne der #CDU darf nicht belohnt werden. https://t.co/mATcCTGbx3', 'hashtags': ['spd', 'cdu'], 'word_count': 41} \n",
      "\n",
      "Tweet 3 \n",
      " {'retweet_count': 0, 'reply_count': 1, 'like_count': 1, 'created_at': '2021-08-27T11:53:07+02:00', 'txt': '@HuebschenH Ja. Das ist wichtig:\\nEs gab eine ganz große Koalition aus #CDU, #FDP &amp; #SPD.\\nUnd eine SPD, die ab 2012 vor Kraft nicht laufen konnte, hat uns Grünen in der Koalition diesen Quatsch abgenötigt.\\nWas lernen wir daraus:\\n#Grüne stärker machen - mit 20% wäre das nicht passiert!', 'hashtags': ['spd', 'cdu', 'fdp', 'grüne'], 'word_count': 46} \n",
      "\n",
      "Tweet 4 \n",
      " {'retweet_count': 3, 'reply_count': 2, 'like_count': 89, 'created_at': '2021-09-02T17:20:59+02:00', 'txt': 'Mehr Klimaschutz, mehr soziale Gerechtigkeit, mehr außenpolitische Verantwortung - das alles gibt es mit unserer Kanzlerkandidatin @ABaerbock! Die Gesellschaft ist so viel weiter als die #GroKo. Es ist Zeit für den Grünen Wechsel - auch in #Bielefeld mit @BriHasselmann! https://t.co/uKbmHDKvEC', 'hashtags': ['groko', 'bielefeld'], 'word_count': 40} \n",
      "\n",
      "Tweet 5 \n",
      " {'retweet_count': 1, 'reply_count': 1, 'like_count': 2, 'created_at': '2021-10-03T22:33:39+02:00', 'txt': 'Die erste #GroKo in Deutschland vereinte 1966 noch 86,9% der Wähler:innen hinter sich. Das lässt sich heute nicht mal mit einer Mosambik-Koalition erreichen. Aber wenn man #CDU und #FDP einerseits und #SPD und #Grüne anderseits beobachtet, könnte man das glatt als Lösung sehen.', 'hashtags': ['spd', 'cdu', 'fdp', 'grüne', 'groko'], 'word_count': 43} \n",
      "\n",
      "Tweet 6 \n",
      " {'retweet_count': 15, 'reply_count': 7, 'like_count': 126, 'created_at': '2021-08-21T13:37:47+02:00', 'txt': '„Es ist inakzeptabel, dass bei #CDU und #SPD niemand Verantwortung übernehmen will, für das Desaster ihrer Politik in #Afghanistan. Am dringlichsten ist jetzt, so viele Menschen zu retten, wie möglich. Dann wird es um Aufklärung gehen!“ \\n\\nStarke Rede von @BriHasselmann #ldk21nrw https://t.co/Wf0yTyeVI6', 'hashtags': ['spd', 'cdu', 'afghanistan', 'ldk21nrw'], 'word_count': 42} \n",
      "\n",
      "Tweet 7 \n",
      " {'retweet_count': 91, 'reply_count': 39, 'like_count': 492, 'created_at': '2021-08-26T21:53:26+02:00', 'txt': '3€ mehr #HartzIV ab 2022. Das ist einfach frech! Dieses menschenunwürdige HartzIV-Regime, das #SPD, #Grüne, #CDU &amp; #FDP groß gemacht haben, muss endlich enden. Artikel 1 des Grundgesetzes gilt für alle! Zeit für eine Mindestsicherung, die jeden vor Armut schützt - sanktionsfrei!', 'hashtags': ['spd', 'hartziv', 'cdu', 'fdp', 'grüne'], 'word_count': 42} \n",
      "\n",
      "Tweet 8 \n",
      " {'retweet_count': 2, 'reply_count': 2, 'like_count': 7, 'created_at': '2021-08-16T08:24:05+02:00', 'txt': '#Afghanistan Katastrophe mit Ansage. 20 Jahre die Dienste der Menschen dort in Anspruch genommen. Außenpolitik der #Bundesregierung =0. Holt alle Menschen in Not raus aus Afghanistan.  #Groko #SPD #CDU wiederholt nicht die Fehler aus Juni 21! @GrueneBundestag @JTrittin @KatjaKeul https://t.co/cG6XYpDYQR', 'hashtags': ['spd', 'cdu', 'afghanistan', 'bundesregierung', 'groko'], 'word_count': 41} \n",
      "\n",
      "Tweet 9 \n",
      " {'retweet_count': 8, 'reply_count': 4, 'like_count': 51, 'created_at': '2021-09-17T09:09:06+02:00', 'txt': 'Für #Klima + #Wohlstand Grün wählen 🌻 Wir erhalten und stärken unsere Freiheit u die kommender Generationen mit konsequentem Klimaschutz. Mit vorausschauender Politik, die die großen Aufgaben anpackt statt einer #Groko, die erst handelt, wenn es zu spät ist. #bereitweilihresseid https://t.co/kzHPldFquN', 'hashtags': ['bereitweilihresseid', 'klima', 'groko', 'wohlstand'], 'word_count': 41} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = es_client.search(index=INDEX, size=SIZE, query=query)\n",
    "\n",
    "print(f'Total of {res[\"hits\"][\"total\"][\"value\"]} hits in {res[\"took\"]}ms \\n')\n",
    "\n",
    "for i, doc in enumerate(res[\"hits\"][\"hits\"]):\n",
    "    print(\"Tweet\", i, \"\\n\", doc[\"_source\"], \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
