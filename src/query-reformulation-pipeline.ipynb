{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy Playground\n",
    "Step by step building a custom pipeline to handle queries for Twitter database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download german package\n",
    "# !python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy init fill-config ../base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsonpy/.local/share/virtualenvs/twitter-query-expansion-tWkdo8vh/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from spacy.language import Language\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Token\n",
    "from spacy import displacy\n",
    "\n",
    "# load german language model\n",
    "nlp = spacy.load('de_core_news_sm', disable=[\"tok2vec\", \"parser\", \"senter\", \"lemmatizer\", \"tagger\", \"attribute_ruler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample query for testing purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"#Angela Merkel im Bundestag #CDU#FDP #merkelmussweg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Investigate Tokens from SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "Angela\n",
      "Merkel\n",
      "im\n",
      "Bundestag\n",
      "#\n",
      "CDU#FDP\n",
      "#\n",
      "merkelmussweg\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(TEXT)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "# displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtags are treated poorly. How to detect them and prevent the tokenizer from splitting them?\n",
    "- split compound hashtags\n",
    "- mark hashtags in SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Preprocessing\n",
    "FIrstly, make sure the whitespaces are set correctly in between the hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Angela Merkel im Bundestag #CDU #FDP #merkelmussweg\n"
     ]
    }
   ],
   "source": [
    "def seperate_hashtags(text: str):\n",
    "    \"\"\"\n",
    "    Insert a whitespace if hashtags are missing a gap in between.  \n",
    "    \"\"\"\n",
    "    for i, j in enumerate(text):\n",
    "        if (text[i] == \"#\" and i > 0):\n",
    "            if text[i-1] != \" \":\n",
    "                    text = text[:i] + \" \" + text[i:]\n",
    "                    i+=1\n",
    "    return text\n",
    "\n",
    "TEXT = seperate_hashtags(TEXT)\n",
    "\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.1 Tokenizer\n",
    "Customize the Matcher to handle Tweet-specific syntax - i.e. hashtags.\n",
    "- Tokenize by Hashtag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.HashtagFinder at 0x7fdb9e03ab30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.factory(\"hashtag_finder\")\n",
    "def create_hashtag_finder(nlp, name):\n",
    "    return HashtagFinder(nlp.vocab)\n",
    "\n",
    "class HashtagFinder:\n",
    "    \"\"\"\n",
    "    The purpose of this class is to detect hashtags and mark them.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab):\n",
    "        patterns = [ [{\"ORTH\": \"#\"}] ]\n",
    "\n",
    "        # Register a new token extension to mark hashtags\n",
    "        Token.set_extension(\"hashtag\", default=False)\n",
    "        self.matcher = Matcher(vocab)\n",
    "        self.matcher.add(\"hashtag_finder\", patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        # This method is invoked when the component is called on a Doc\n",
    "        matches = self.matcher(doc)\n",
    "        spans = []  # Collect the matched spans here\n",
    "\n",
    "        for match_id, start, end in matches:\n",
    "            # TODO: what happens if whitespace after hashtag? \n",
    "            if (end < len(doc)):\n",
    "                spans.append(doc[start+1:end+1])\n",
    "            \n",
    "        with doc.retokenize() as retokenizer:\n",
    "            for span in spans:\n",
    "                retokenizer.merge(span)\n",
    "                for token in span:\n",
    "                    token._.hashtag = True  # Mark token as hashtag\n",
    "        return doc\n",
    "     \n",
    "nlp.add_pipe(\"hashtag_finder\", before=\"ner\")  # Add component to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# False\n",
      "Angela True\n",
      "Merkel False\n",
      "im False\n",
      "Bundestag False\n",
      "# False\n",
      "CDU True\n",
      "# False\n",
      "FDP True\n",
      "# False\n",
      "merkelmussweg True\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(TEXT)\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token._.hashtag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.2 Named Entities\n",
    "How are named entities detected? Especially those that are hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angela Merkel 1 14 Named person or family.\n",
      "Bundestag 18 27 Companies, agencies, institutions, etc.\n",
      "CDU 29 32 Companies, agencies, institutions, etc.\n",
      "#\n",
      "Angela\n",
      "Merkel\n",
      "im\n",
      "Bundestag\n",
      "#\n",
      "CDU\n",
      "#\n",
      "FDP\n",
      "#\n",
      "merkelmussweg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">#\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Angela Merkel\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " im \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bundestag\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " #\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    CDU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " #FDP #merkelmussweg</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(TEXT)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, spacy.explain(ent.label_))\n",
    "\n",
    "for token in doc:\n",
    "    print(token)\n",
    "    \n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that named entities as well as hashtags are treated correctly. Now, let's have a look at which terms are relevant for POS Tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1.3 Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Word Embeddings\n",
    "The following embeddings are applied to the selected terms\n",
    "-FastText\n",
    "-Glove\n",
    "-Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
