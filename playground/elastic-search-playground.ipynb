{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Search Playground\n",
    "First, load the credentials to connect the elastic search client and the posgres database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "es_cred = json.load(open('../es-credentials.json'))\n",
    "pg_cred = json.load(open('../pg-credentials.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the Elastic Search instance is running either by\n",
    "- elastic search python library\n",
    "- basic https request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import psycopg2\n",
    "\n",
    "def es_connect(credentials: json):\n",
    "    \"\"\"\n",
    "    Connect to an elastic search API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Connecting to Elastic Search...\")\n",
    "        es = Elasticsearch(es_cred['URL'], basic_auth=(es_cred['USER'], es_cred['PWD']), ca_certs=es_cred['CERT'])\n",
    "    except Exception:\n",
    "        print(\"Unable to connect to\", credentials['URL'])\n",
    "        exit(1)\n",
    "    print(\"Successfully connected to\", credentials['URL'])\n",
    "    return es\n",
    "\n",
    "\n",
    "def pg_connect(credentials: json):\n",
    "    \"\"\"\n",
    "    Connect to a PostgreSQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Connecting to PostgreSQL database...\")\n",
    "        pg = psycopg2.connect(dbname=credentials[\"DB\"], user=credentials['USER'], password=credentials['PWD'])\n",
    "    except Exception:\n",
    "        print(\"Failed to connect to PostgresQL database \", credentials['URL'])\n",
    "    print(\"Successfully connected to\", credentials['URL'])\n",
    "    return pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'f6240d32ea65', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'YIiFu2p-QOWJhSPb-Zcavw', 'version': {'number': '8.5.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'a846182fa16b4ebfcc89aa3c11a11fd5adf3de04', 'build_date': '2022-11-17T18:56:17.538630285Z', 'build_snapshot': False, 'lucene_version': '9.4.1', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to elastic instance\n",
    "es_client = es_connect(credentials=es_cred)\n",
    "\n",
    "# Get info of API\n",
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# access API via http request\n",
    "requests.get(es_cred['URL'], auth=(es_cred['USER'], es_cred['PWD']), verify=es_cred['CERT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project the elastic search python package is utilized. Let's check the overall status of the elastic search instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'cluster_name': 'docker-cluster', 'status': 'yellow', 'timed_out': False, 'number_of_nodes': 1, 'number_of_data_nodes': 1, 'active_primary_shards': 15, 'active_shards': 15, 'relocating_shards': 0, 'initializing_shards': 0, 'unassigned_shards': 2, 'delayed_unassigned_shards': 0, 'number_of_pending_tasks': 0, 'number_of_in_flight_fetch': 0, 'task_max_waiting_in_queue_millis': 0, 'active_shards_percent_as_number': 88.23529411764706})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.cluster.health()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Index for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.indices.create(index=\"tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client.indices.delete(index=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feed data into ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to feed data from the Twitter PostgreSQL database into Elastic Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(cursor, attributes, size=100):\n",
    "    \"\"\"\n",
    "    An iterator that returns objects from a PostgreSQL database connection.\n",
    "    The objects are turned into dictionaries of a certain shape defined by attributes. \n",
    "    \"\"\"\n",
    "    while True:\n",
    "        results = cursor.fetchmany(size)\n",
    "        if not results:\n",
    "            break\n",
    "\n",
    "        for result in results:\n",
    "            obj = {}\n",
    "            for i, attr in enumerate(attributes):\n",
    "                obj[attr] = result[i]\n",
    "            yield obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL database...\n",
      "Successfully connected to localhost:5432\n",
      "Executing Query\n",
      " SELECT * FROM ( SELECT id, conversation_id, author_id, retweet_count, reply_count, like_count, created_at, txt, array_length(string_to_array(regexp_replace(txt,  '[^\\w\\s]', '', 'g'), ' '), 1) AS word_count FROM tweet) AS t WHERE word_count >= 25 \n"
     ]
    }
   ],
   "source": [
    "# connect to postgres and retrieve cursor object\n",
    "pg_cursor = pg_connect(credentials=pg_cred).cursor()\n",
    "\n",
    "# selected attributes from postgres twitter table\n",
    "# CAVEAT: order matters!\n",
    "ATTRIBUTES = [\"id\", \"conversation_id\", \"author_id\", \"retweet_count\", \"reply_count\", \"like_count\", \"created_at\", \"txt\", \"word_count\"]\n",
    "\n",
    "# filter the tweets to have at least a certain number of words\n",
    "WORD_COUNT = 25\n",
    "\n",
    "# formulate query to add number of words within a tweet text\n",
    "word_count_query = (\n",
    "    f\"SELECT {', '.join(ATTRIBUTES)}, array_length(string_to_array(regexp_replace(txt,  '[^\\w\\s]', '', 'g'), ' '), 1) AS word_count FROM tweet)\"\n",
    ")\n",
    "\n",
    "# compose final query\n",
    "pg_query = (\n",
    "    f\"SELECT * FROM ( \"\n",
    "    f\"{word_count_query} AS t \" \n",
    "    f\"WHERE word_count >= {WORD_COUNT} \"\n",
    ")\n",
    "\n",
    "# execute the query\n",
    "print(\"Executing Query\\n\", pg_query)\n",
    "pg_cursor.execute(query=pg_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "190826it [1:44:01, 30.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# insert data from Postgres to ES in a lazy manner\n",
    "for data in tqdm(iterate(cursor=pg_cursor, attributes=ATTRIBUTES, size=1000)):\n",
    "    # insert data into ES\n",
    "    try:\n",
    "        # parse the id to avoid duplicates\n",
    "        es_client.index(index=\"tweets\", document=data, id=data[\"id\"])\n",
    "    except Exception as exc:\n",
    "        print(\"Exception during data insertion!\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Search data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_query = {\n",
    "      \"match\": {\n",
    "        \"txt\": \"Ma√ü Bier\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'tweets',\n",
       "  '_id': '1443707088392409095',\n",
       "  '_score': 16.841162,\n",
       "  '_source': {'id': 1443707088392409095,\n",
       "   'conversation_id': 1443707088392409095,\n",
       "   'author_id': 235703405,\n",
       "   'retweet_count': 6,\n",
       "   'reply_count': 5,\n",
       "   'like_count': 82,\n",
       "   'created_at': '2021-10-01T00:39:27+02:00',\n",
       "   'txt': 'Ich finde, CSU‚Äôler wie #Ramsauer w√§ren auf dem Oktoberfest bei einem Schweinshaxen und einer Ma√ü Bier besser aufgehoben als bei einer Talkshow von Markus #Lanz!'}},\n",
       " {'_index': 'tweets',\n",
       "  '_id': '1423614844863979527',\n",
       "  '_score': 9.578211,\n",
       "  '_ignored': ['txt.keyword'],\n",
       "  '_source': {'id': 1423614844863979527,\n",
       "   'conversation_id': 1423614844863979527,\n",
       "   'author_id': 940691491835564033,\n",
       "   'retweet_count': 1,\n",
       "   'reply_count': 0,\n",
       "   'like_count': 9,\n",
       "   'created_at': '2021-08-06T14:00:03+02:00',\n",
       "   'txt': 'Heute ist der Internationale Tag des #Bieres, d.h.:\\n1Ô∏è‚É£ #Freunde treffen, um gemeinsam Bier zu genie√üen.\\n2Ô∏è‚É£Die M√§nner und Frauen zu ehren, welche das Bier brauen und servieren.\\n3Ô∏è‚É£Biere aller Nationen und Kulturen zu feiern und damit die Welt zu #vereinen. In diesem Sinne, Prost üçª https://t.co/bLOUHjIX5Y'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = es_client.search(index=\"tweets\", size=2, query=es_query)\n",
    "res[\"hits\"][\"hits\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('twitter-query-expansion-tWkdo8vh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
