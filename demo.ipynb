{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Expansion\n",
    "© Jason Pyanowski\n",
    "\n",
    "In this demo file, the application of the project **Twitter Query Expansion** is explained. Starting with the initial Tweets data retrieval and download of the Word Embedding models. Then the pipeline is invoked and the configurations are elaborated.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Twitter Data Preparation\n",
    "Parse Tweets from the PostgreSQL database into an Elastic Search Index. This task is handled by the script `/scripts/tweet_feeder.py` as stated below. It is required to have a running Elastic Search Cluster and a PostgreSQL database at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tweet_feeder.py [-h] -i INDEX -t TABLE [-ec ELASTIC_CREDENTIALS]\n",
      "                       [-pc POSTGRES_CREDENTIALS] [-es ELASTIC_SETTINGS]\n",
      "                       [-wc WORDCOUNT]\n",
      "\n",
      "Feed Postgres data into Elastic Search Index\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i INDEX, --index INDEX\n",
      "                        Elastic Search index\n",
      "  -t TABLE, --table TABLE\n",
      "                        Postgres table\n",
      "  -ec ELASTIC_CREDENTIALS, --elastic_credentials ELASTIC_CREDENTIALS\n",
      "                        Path to Elastic Search credentials file\n",
      "  -pc POSTGRES_CREDENTIALS, --postgres_credentials POSTGRES_CREDENTIALS\n",
      "                        Path to Postgres credentials file\n",
      "  -es ELASTIC_SETTINGS, --elastic_settings ELASTIC_SETTINGS\n",
      "                        Settings for new Index; Look at \"/templates/es-\n",
      "                        config.conf\"\n",
      "  -wc WORDCOUNT, --wordcount WORDCOUNT\n",
      "                        Minimum number of words per Tweet\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/tweet_feeder.py -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Download Word Embedding Models\n",
    "This Pipeline allows tu use different word embedding models. The download link of the desired model can be used to load the model below. The model types of `fasttext` and `word2vec` are currently supported. To speed up the performance of the query expansion pipeline, the models are consequently compressed.\n",
    "\n",
    "|Parameter|Possible Values|Datatype|\n",
    "|---|---|---|\n",
    "|type|`'fasttext'`, `'word2vec'`|`str`|\n",
    "|url|`'url to model'`|`str`|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download Word2Vec model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_loader import load_model\n",
    "load_model(type=\"word2vec\", url=\"https://cloud.devmount.de/d2bc5672c523b086/german.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download FastText model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(type=\"fasttext\", url=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Pipeline Configuration\n",
    "### Define Queries\n",
    "Specify queries on which to evaluate the pipeline. Queries may include Twitter-specific syntax like hashtags `#EU` or user mentions `@bundestag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"große Koalition gescheitert unter Merkel? #Groko #SPD #CDU\",\n",
    "    \"Lauterbach Deutschland Corona-Maßnahmen #Impfung\",\n",
    "    \"@bundestag Bundestagswahl 2021 Ergebnisse\",\n",
    "    #\"EU Brexit Boris Johnson\",\n",
    "    \"Gesetzliche Rentenversicherung Rente Mit 67\",\n",
    "    #\"Klimapolitik Deutschland #Grüne\",\n",
    "    #\"Asylpolitik Merkel\",\n",
    "    #\"Soli abschaffen Westen\",\n",
    "    \"Bundeswehr Afghanistan Krieg stoppen\",\n",
    "    #\"Deutschland Energiewende mit SPD CDU\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Word Embedding Parameters\n",
    "In order to obtain the desired results, modify the parameters for Word Embeddings. These configurations determine which of the initial query terms are actually used to find related terms.\n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|type|`'word2vec', 'fasttext'`|`str`|\n",
    "|model| `'path to model'`|`str`|\n",
    "|pos_list|`['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'EOL', 'IDS', 'INTJ', 'NAMES', 'NOUN', 'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']`| `list[str]`|\n",
    "|entity_list|`['LOC', 'MISC', 'ORG', 'PER']`|`list[str]`|\n",
    "|hashtag|`True, False`|`bool`|\n",
    "|user|`True, False`|`bool`|\n",
    "|num_nearest_terms|`1...N`|`int`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PARAMS = {\n",
    "    \"type\": \"word2vec\",\n",
    "    \"model\": \"models/word2vec/german.model\",\n",
    "    \"pos_list\": [\"NOUN\",\"ADJ\",\"VERB\",\"PROPN\"],\n",
    "    \"entity_list\": ['LOC', 'ORG'],\n",
    "    \"hashtag\": True,\n",
    "    \"user\": False,\n",
    "    \"num_nearest_terms\": 3\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Elastic Search Parameters\n",
    "After Query Expansion, the Tweets are retrieved from an Elastic Search Index. Specify the parameters below and make sure that an Index is running on your machine. \n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|index|`'tweets'`|`str`|\n",
    "|num_of_tweets|`1...N`| `int`|\n",
    "|retweet|`True, False`|`bool`|\n",
    "|hashtag_boost|`0...N`|`float`|\n",
    "|tweet_range|`(date, date)`|`tuple`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_PARAMS = {\n",
    "    \"index\": \"tweets_all\",\n",
    "    \"num_of_tweets\": 20,\n",
    "    \"retweet\": False,\n",
    "    \"hashtag_boost\": 1.0,\n",
    "    \"tweet_range\": (\"2020-01-01\", \"2023-01-01\")\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Execute Pipeline\n",
    "Run the Pipeline - the results are stored in the `/output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text using SpaCy...\n",
      "Evaluating word2vec model...\n",
      "Connecting to Elastic Search...\n",
      "Retrieving Tweets...\n",
      "Writing results to output/word2vec/18-01-23_16-51-42\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "from scripts import pipeline\n",
    "\n",
    "res = pipeline.run(\n",
    "    queries=QUERIES, \n",
    "    embedding_params=EMBEDDING_PARAMS,\n",
    "    elastic_params=ELASTIC_PARAMS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Inspect Results\n",
    "Load results and have a look through the retrieved Tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: große Koalition gescheitert unter Merkel? #Groko #SPD #CDU\n",
      "Tweet:  Die erste #GroKo in Deutschland vereinte 1966 noch 86,9% der Wähler:innen hinter sich. Das lässt sich heute nicht mal mit einer Mosambik-Koalition erreichen. Aber wenn man #CDU und #FDP einerseits und #SPD und #Grüne anderseits beobachtet, könnte man das glatt als Lösung sehen.\n",
      "Tweet:  Aber…. Ach so, das wollten ja #SPD #CDU und #CSU explizit nicht. Obwohl Grüne, FDP und Linke das beantragt hatten. Die #GroKo nimmt es schlicht billigend in Kauf, dass bis zu 300 Abgeordnete mehr in den Bundestag kommen. Es wäre schlicht verheerend.\n",
      "Tweet:  Bis zu 1000 Abgeordnete könnte der neue #Bundestag nach der Wahl bekommen! Die #FDP hatte mit anderen Oppositionsparteien eine effektive #Wahlrechtsreform auf den Weg gebracht. Stattdessen hat sich die #GroKo aus #CDUCSU und #SPD für dieses Reförmchen ohne Wirkung gefeiert. @fdp https://t.co/VZJ1k0dbyW\n",
      "\n",
      "\n",
      "Query: Lauterbach Deutschland Corona-Maßnahmen #Impfung\n",
      "Tweet:  3-G bleibt – kostenlose #Corona Tests fallen ab 11.10. weg (Ausnahme: #Impfung nicht möglich / keine Impfempfehlung). Malu #Dreyer: #Impfquote entscheidend für Herbst &amp; Winter und zur Verhinderung weiteren #Lockdown. #RLP hat alles darangesetzt, #Impfen zu erleichtern. https://t.co/V7FjssslkB\n",
      "Tweet:  Netzfund!\n",
      "\"Sag doch mal die Wahrheit, Karl!\"\n",
      "#Lauterbach #Lanz #Corona #Pandemie #Bundestagswahl \n",
      "#Impfung #Impfpflicht #Impfdurchbruch #Impfpass https://t.co/EnYaCCuq2D\n",
      "Tweet:  Entgegen dem Sachverstand der #STIKO und der Kritik des Deutschen Hausärzteverbandes wollen Politiker Kindern einen Impfstoff mit nur bedingter Zulassung zumuten. \n",
      "\n",
      "https://t.co/heZ1KJeFHS\n",
      "\n",
      "#Spahn #Corona #Impfung #Kinderimpfung https://t.co/s40NAA4uKi\n",
      "\n",
      "\n",
      "Query: @bundestag Bundestagswahl 2021 Ergebnisse\n",
      "Tweet:  Vielen Dank an alle Wählerinnen und Wähler, ich darf im 20.Deutschen Bundestag weiter mitarbeiten. Im Saarland ein historisch starkes FDP Ergebnis. 💪🙏 https://t.co/0sIuz6YxzM\n",
      "Tweet:  Was die viel zitierte Disziplin der Kanzlertauglichkeit angeht, fällt das Ergebnis zwischen den drei Aspirant(inn)en ziemlich eindeutig zugunsten von @OlafScholz aus.\n",
      "Jetzt müssen wir als @spdde noch eine Schippe drauf legen in den verbleibenden Wochen bis zur Bundestagswahl!\n",
      "Tweet:  Ich bin zurück in #Berlin für #Mannheim &amp; werde kämpfen. Unser Ergebnis ist enttäuschend &amp; gleichzeitig Ansporn. Der Prozess der Neufindung startet heute. Wir bleiben das soziale Gewissen im Bundestag @Linksfraktion \n",
      "\n",
      "Danke an alle die mich unterstützt &amp; die #LINKE gewählt haben. https://t.co/E13I54QJGf\n",
      "\n",
      "\n",
      "Query: Gesetzliche Rentenversicherung Rente Mit 67\n",
      "Tweet:  @Caritas_web @diegruenen @tpflueger @dieLinke @JuliaSoehne @spdbt @grimmsi1 @DieHumanisten @AlexanderGrevel @Klimaliste (7/7) last but not least: Wertschätzung braucht auch Löhne, die sie bezeugen – am besten über gute Tarifverträge. Wir wollen die gesetzliche Pflegeversicherung verpflichten, nur noch mit Anbietern zusammenzuarbeiten, die nach Tarif bezahlen.\n",
      "Tweet:  Liebe @maybritillner &amp; @koehroliver, falls Sie noch Fragen für das heutige #Triell entgegen nehmen: der #Pflegenotstand und der #Fachkräftemangel im Gesundheitswesen gefährdet die Gesundheitsversorgung. Es fehlen Mrd. Beträge in der Gesetzlichen Kranken- &amp; der Pflegeversicherung\n",
      "Tweet:  -   Keine Rentenkürzungen\n",
      "-   Keine Anhebung des Renteneintrittsalters\n",
      "-   Einstieg in teilweise Kapitaldeckung der Gesetzlichen Rentenversicherung.\n",
      "-   Abschaffung von Hartz IV! Stattdessen Einführung von Bürgergeld.\n",
      "-   Erhalt der privaten Kranken- und Pflegeversicherung.\n",
      "(4/7)\n",
      "\n",
      "\n",
      "Query: Bundeswehr Afghanistan Krieg stoppen\n",
      "Tweet:  Nach dem Scheitern des 20-jährigen @NATO-Krieges in #Afghanistan die #Bundeswehr zurück an den Hindukusch schicken zu wollen, um den Vormarsch der #Taliban zu stoppen, ist der Gipfel an Hilflosigkeit, Unentschlossenheit und völlig verantwortungslos. https://t.co/NdAM3JReOI\n",
      "Tweet:  @GermanCucumber1 @dieLinke OK, was ist das Problem? Stopp Abschiebungen nach Afghanistan? Stopp Rüstungsexporte in Krisenregionen? Diplomatie statt Eskalation? Oder dass wir auf lange Perspektive Kriegsbündnis NATO in ein Bündnis kollektiver Sicherheit umwandeln und die Vereinten Nationen stärken wollen?\n",
      "Tweet:  Ganz im Sinne #Laschet|s könnte schon morgen die nächste #Abschiebung nach #Afghanistan gehen - trotz Krieg, Terror, #Pandemie u der Bitte der afghanischen Regierung nach Abschiebestopp. Heuchlerisch anmutend auch die Kritik der SPD, die 40 Sammelabschiebungen mitgetragen hat! https://t.co/W7ZGgAtKSm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweets, query in zip(res, QUERIES):\n",
    "    print(\"Query:\",query)\n",
    "    \n",
    "    for tweet in tweets[\"tweets\"][:3]:\n",
    "        print(\"Tweet: \", tweet[\"_source\"][\"txt\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-query-expansion-tWkdo8vh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
