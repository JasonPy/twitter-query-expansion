{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Expansion\n",
    "© Jason Pyanowski\n",
    "\n",
    "In this demo file, the application of the project **Twitter Query Expansion** is explained. Starting with the initial data retrieval and doanload of the Word Embedding models. Then the pipeline is invoked and the results are inspected. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "To work with some data, the Database Systems Research Group provided a PostgreSQL database dump. This includes german Tweets over a period of about two years related with politics. To make use of them, an Elastic Search index is fed with this data. This allows to search Tweets quickly. In order to make use of this, the Tweets must be parsed from the PostgreSQL database into an Elastic Search Index. This task is handled by the script `/scripts/tweet_feeder.py` as stated below. Make sure to have access to a database and a running Elastic Cluster. Also run this script outside of a jupyter notebook to significantly increase running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/tweet_feeder.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 scripts/tweet_feeder.py -i tweets -t tweet -wc 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "This Pipeline allows tu use different word embedding models. The download link of the desired model can be used to load the model below. The model types of `fasttext` and `word2vec` are currently supported. To speed up the performance of the query expansion pipeline, the models are consequently compressed.\n",
    "\n",
    "|Parameter|Possible Values|Datatype|\n",
    "|---|---|---|\n",
    "|type|`'fasttext'`, `'word2vec'`|`str`|\n",
    "|url|`'url to model'`|`str`|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_loader import load_model\n",
    "load_model(type=\"word2vec\", url=\"https://cloud.devmount.de/d2bc5672c523b086/german.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(type=\"fasttext\", url=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Queries\n",
    "Specify queries on which to evaluate the pipeline. Queries may include Twitter-specific syntax like hashtags `#EU` or user mentions `@bundestag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"große Koalition gescheitert unter Merkel? #Groko #SPD #CDU\",\n",
    "    \"Lauterbach Deutschland Corona-Maßnahmen #Impfung\",\n",
    "    \"@bundestag Bundestagswahl 2021 Ergebnisse\",\n",
    "    \"Europäische Union Brexit Boris Johnson\",\n",
    "    \"Gesetzliche Rentenversicherung Rente Mit 67\",\n",
    "    \"Klimapolitik Deutschland #Grüne\",\n",
    "    \"Asylpolitik Merkel\",\n",
    "    \"Soli abschaffen im Westen\",\n",
    "    \"Bundeswehr Afghanistan Krieg stoppen\",\n",
    "    \"Deutschland Energiewende unter SPD CDU\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Word Embedding Parameters\n",
    "In order to obtain the desired results, modify the parameters for Word Embeddings. These configurations determine which of the initial query terms are actually used to find related terms.\n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|type|`'word2vec', 'fasttext'`|`str`|\n",
    "|model| `'path to model'`|`str`|\n",
    "|pos_list|`['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'EOL', 'IDS', 'INTJ', 'NAMES', 'NOUN', 'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']`| `list[str]`|\n",
    "|entity_list|`['LOC', 'MISC', 'ORG', 'PER']`|`list[str]`|\n",
    "|hashtag|`True, False`|`bool`|\n",
    "|user|`True, False`|`bool`|\n",
    "|num_nearest_terms|`1...N`|`int`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PARAMS = {\n",
    "    \"type\": \"word2vec\",\n",
    "    \"model\": \"models/word2vec/german.model\",\n",
    "    \"pos_list\": [\"NOUN\",\"ADJ\",\"VERB\",\"PROPN\"],\n",
    "    \"entity_list\": ['LOC', 'ORG'],\n",
    "    \"hashtag\": False,\n",
    "    \"user\": False,\n",
    "    \"num_nearest_terms\": 5\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Elastic Search Parameters\n",
    "After Query Expansion, the Tweets are retrieved from an Elastic Search Index. Specify the parameters below and make sure that an Index is running on your machine. \n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|index|`'tweets'`|`str`|\n",
    "|num_of_tweets|`1...N`| `int`|\n",
    "|retweet|`True, False`|`bool`|\n",
    "|hashtag_boost|`0...N`|`float`|\n",
    "|tweet_range|`(date, date)`|`tuple`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_PARAMS = {\n",
    "    \"index\": \"tweets\",\n",
    "    \"num_of_tweets\": 10,\n",
    "    \"retweet\": False,\n",
    "    \"hashtag_boost\": 0.5,\n",
    "    \"tweet_range\": (\"2021-01-01\", \"2023-01-01\")\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Pipeline\n",
    "Run the Pipeline - the results are stored in the `/out` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text using SpaCy...\n",
      "Evaluating word2vec model...\n",
      "Connecting to Elastic Search...\n",
      "Successfully connected to https://localhost:9200\n",
      "Retrieving Tweets...\n",
      "Writing results to out/word2vec/11-01-23_19-13-11\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "from scripts import pipeline\n",
    "\n",
    "res = pipeline.run(\n",
    "    queries=QUERIES, \n",
    "    embedding_params=EMBEDDING_PARAMS,\n",
    "    elastic_params=ELASTIC_PARAMS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Results\n",
    "Load results and have a look through the retrieved Tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweets, i in zip(res,range(len(QUERIES))):\n",
    "    print(\"Query:\", QUERIES[i], \"\\n\")\n",
    "    for tweet in tweets[\"tweets\"]:\n",
    "        print(\"->\", tweet[\"_source\"][\"txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-query-expansion-tWkdo8vh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
