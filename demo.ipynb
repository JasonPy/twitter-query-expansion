{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Query Expansion\n",
    "¬© Jason Pyanowski\n",
    "\n",
    "In this demo file, the application of the project **Twitter Query Expansion** is explained. Starting with the initial Tweets data retrieval and download of the Word Embedding models. Then the pipeline is invoked and the configurations are elaborated.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Twitter Data Preparation\n",
    "Parse Tweets from the PostgreSQL database into an Elastic Search Index. This task is handled by the script `/scripts/tweet_feeder.py` as stated below. It is required to have a running Elastic Search Cluster and a PostgreSQL database at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tweet_feeder.py [-h] -i INDEX -t TABLE [-ec ELASTIC_CREDENTIALS]\n",
      "                       [-pc POSTGRES_CREDENTIALS] [-es ELASTIC_SETTINGS]\n",
      "                       [-wc WORDCOUNT]\n",
      "\n",
      "Feed Postgres data into Elastic Search Index\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -i INDEX, --index INDEX\n",
      "                        Elastic Search index\n",
      "  -t TABLE, --table TABLE\n",
      "                        Postgres table\n",
      "  -ec ELASTIC_CREDENTIALS, --elastic_credentials ELASTIC_CREDENTIALS\n",
      "                        Path to Elastic Search credentials file\n",
      "  -pc POSTGRES_CREDENTIALS, --postgres_credentials POSTGRES_CREDENTIALS\n",
      "                        Path to Postgres credentials file\n",
      "  -es ELASTIC_SETTINGS, --elastic_settings ELASTIC_SETTINGS\n",
      "                        Settings for new Index; Look at \"/templates/es-\n",
      "                        config.conf\"\n",
      "  -wc WORDCOUNT, --wordcount WORDCOUNT\n",
      "                        Minimum number of words per Tweet\n"
     ]
    }
   ],
   "source": [
    "!python3 scripts/tweet_feeder.py -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Download Word Embedding Models\n",
    "This Pipeline allows tu use different word embedding models. The download link of the desired model can be used to load the model below. The model types of `fasttext` and `word2vec` are currently supported. To speed up the performance of the query expansion pipeline, the models are consequently compressed.\n",
    "\n",
    "|Parameter|Possible Values|Datatype|\n",
    "|---|---|---|\n",
    "|type|`'fasttext'`, `'word2vec'`|`str`|\n",
    "|url|`'url to model'`|`str`|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download Word2Vec model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.model_loader import load_model\n",
    "load_model(type=\"word2vec\", url=\"https://cloud.devmount.de/d2bc5672c523b086/german.model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download FastText model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(type=\"fasttext\", url=\"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.de.300.vec.gz\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Pipeline Configuration\n",
    "### Define Queries\n",
    "Specify queries on which to evaluate the pipeline. Queries may include Twitter-specific syntax like hashtags `#EU` or user mentions `@bundestag`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERIES = [\n",
    "    \"gro√üe Koalition gescheitert unter Merkel? #Groko #SPD #CDU\",\n",
    "    \"Lauterbach Deutschland Corona-Ma√ünahmen #Impfung\",\n",
    "    \"@bundestag Bundestagswahl 2021 Ergebnisse\",\n",
    "    #\"EU Brexit Boris Johnson\",\n",
    "    \"Gesetzliche Rentenversicherung Rente Mit 67\",\n",
    "    #\"Klimapolitik Deutschland #Gr√ºne\",\n",
    "    #\"Asylpolitik Merkel\",\n",
    "    #\"Soli abschaffen Westen\",\n",
    "    \"Bundeswehr Afghanistan Krieg stoppen\",\n",
    "    #\"Deutschland Energiewende mit SPD CDU\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Word Embedding Parameters\n",
    "In order to obtain the desired results, modify the parameters for Word Embeddings. These configurations determine which of the initial query terms are actually used to find related terms.\n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|type|`'word2vec', 'fasttext'`|`str`|\n",
    "|model| `'path to model'`|`str`|\n",
    "|pos_list|`['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'CONJ', 'DET', 'EOL', 'IDS', 'INTJ', 'NAMES', 'NOUN', 'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB', 'X']`| `list[str]`|\n",
    "|entity_list|`['LOC', 'MISC', 'ORG', 'PER']`|`list[str]`|\n",
    "|hashtag|`True, False`|`bool`|\n",
    "|user|`True, False`|`bool`|\n",
    "|num_nearest_terms|`1...N`|`int`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PARAMS = {\n",
    "    \"type\": \"word2vec\",\n",
    "    \"model\": \"models/word2vec/german.model\",\n",
    "    \"pos_list\": [\"NOUN\",\"ADJ\",\"VERB\",\"PROPN\"],\n",
    "    \"entity_list\": ['LOC', 'ORG'],\n",
    "    \"hashtag\": True,\n",
    "    \"user\": False,\n",
    "    \"num_nearest_terms\": 3\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Elastic Search Parameters\n",
    "After Query Expansion, the Tweets are retrieved from an Elastic Search Index. Specify the parameters below and make sure that an Index is running on your machine. \n",
    "\n",
    "| Parameter | Possible Values | Datatype |\n",
    "|---|---|---|\n",
    "|index|`'tweets'`|`str`|\n",
    "|num_of_tweets|`1...N`| `int`|\n",
    "|retweet|`True, False`|`bool`|\n",
    "|hashtag_boost|`0...N`|`float`|\n",
    "|tweet_range|`(date, date)`|`tuple`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_PARAMS = {\n",
    "    \"index\": \"tweets_all\",\n",
    "    \"num_of_tweets\": 20,\n",
    "    \"retweet\": False,\n",
    "    \"hashtag_boost\": 1.0,\n",
    "    \"tweet_range\": (\"2020-01-01\", \"2023-01-01\")\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Execute Pipeline\n",
    "Run the Pipeline - the results are stored in the `/output` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text using SpaCy...\n",
      "Evaluating word2vec model...\n",
      "Connecting to Elastic Search...\n",
      "Retrieving Tweets...\n",
      "Writing results to output/word2vec/18-01-23_16-51-42\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# run pipeline\n",
    "from scripts import pipeline\n",
    "\n",
    "res = pipeline.run(\n",
    "    queries=QUERIES, \n",
    "    embedding_params=EMBEDDING_PARAMS,\n",
    "    elastic_params=ELASTIC_PARAMS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Inspect Results\n",
    "Load results and have a look through the retrieved Tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: gro√üe Koalition gescheitert unter Merkel? #Groko #SPD #CDU\n",
      "Tweet:  Die erste #GroKo in Deutschland vereinte 1966 noch 86,9% der W√§hler:innen hinter sich. Das l√§sst sich heute nicht mal mit einer Mosambik-Koalition erreichen. Aber wenn man #CDU und #FDP einerseits und #SPD und #Gr√ºne anderseits beobachtet, k√∂nnte man das glatt als L√∂sung sehen.\n",
      "Tweet:  Aber‚Ä¶. Ach so, das wollten ja #SPD #CDU und #CSU explizit nicht. Obwohl Gr√ºne, FDP und Linke das beantragt hatten. Die #GroKo nimmt es schlicht billigend in Kauf, dass bis zu 300 Abgeordnete mehr in den Bundestag kommen. Es w√§re schlicht verheerend.\n",
      "Tweet:  Bis zu 1000 Abgeordnete k√∂nnte der neue #Bundestag nach der Wahl bekommen! Die #FDP hatte mit anderen Oppositionsparteien eine effektive #Wahlrechtsreform auf den Weg gebracht. Stattdessen hat sich die #GroKo aus #CDUCSU und #SPD f√ºr dieses Ref√∂rmchen ohne Wirkung gefeiert. @fdp https://t.co/VZJ1k0dbyW\n",
      "\n",
      "\n",
      "Query: Lauterbach Deutschland Corona-Ma√ünahmen #Impfung\n",
      "Tweet:  3-G bleibt ‚Äì kostenlose #Corona Tests fallen ab 11.10. weg (Ausnahme: #Impfung nicht m√∂glich / keine Impfempfehlung). Malu #Dreyer: #Impfquote entscheidend f√ºr Herbst &amp; Winter und zur Verhinderung weiteren #Lockdown. #RLP hat alles darangesetzt, #Impfen zu erleichtern. https://t.co/V7FjssslkB\n",
      "Tweet:  Netzfund!\n",
      "\"Sag doch mal die Wahrheit, Karl!\"\n",
      "#Lauterbach #Lanz #Corona #Pandemie #Bundestagswahl \n",
      "#Impfung #Impfpflicht #Impfdurchbruch #Impfpass https://t.co/EnYaCCuq2D\n",
      "Tweet:  Entgegen dem Sachverstand der #STIKO und der Kritik des Deutschen Haus√§rzteverbandes wollen Politiker Kindern einen Impfstoff mit nur bedingter Zulassung zumuten. \n",
      "\n",
      "https://t.co/heZ1KJeFHS\n",
      "\n",
      "#Spahn #Corona #Impfung #Kinderimpfung https://t.co/s40NAA4uKi\n",
      "\n",
      "\n",
      "Query: @bundestag Bundestagswahl 2021 Ergebnisse\n",
      "Tweet:  Vielen Dank an alle W√§hlerinnen und W√§hler, ich darf im 20.Deutschen Bundestag weiter mitarbeiten. Im Saarland ein historisch starkes FDP Ergebnis. üí™üôè https://t.co/0sIuz6YxzM\n",
      "Tweet:  Was die viel zitierte Disziplin der Kanzlertauglichkeit angeht, f√§llt das Ergebnis zwischen den drei Aspirant(inn)en ziemlich eindeutig zugunsten von @OlafScholz aus.\n",
      "Jetzt m√ºssen wir als @spdde noch eine Schippe drauf legen in den verbleibenden Wochen bis zur Bundestagswahl!\n",
      "Tweet:  Ich bin zur√ºck in #Berlin f√ºr #Mannheim &amp; werde k√§mpfen. Unser Ergebnis ist entt√§uschend &amp; gleichzeitig Ansporn. Der Prozess der Neufindung startet heute. Wir bleiben das soziale Gewissen im Bundestag @Linksfraktion \n",
      "\n",
      "Danke an alle die mich unterst√ºtzt &amp; die #LINKE gew√§hlt haben. https://t.co/E13I54QJGf\n",
      "\n",
      "\n",
      "Query: Gesetzliche Rentenversicherung Rente Mit 67\n",
      "Tweet:  @Caritas_web @diegruenen @tpflueger @dieLinke @JuliaSoehne @spdbt @grimmsi1 @DieHumanisten @AlexanderGrevel @Klimaliste (7/7) last but not least: Wertsch√§tzung braucht auch L√∂hne, die sie bezeugen ‚Äì am besten √ºber gute Tarifvertr√§ge. Wir wollen die gesetzliche Pflegeversicherung verpflichten, nur noch mit Anbietern zusammenzuarbeiten, die nach Tarif bezahlen.\n",
      "Tweet:  Liebe @maybritillner &amp; @koehroliver, falls Sie noch Fragen f√ºr das heutige #Triell entgegen nehmen: der #Pflegenotstand und der #Fachkr√§ftemangel im Gesundheitswesen gef√§hrdet die Gesundheitsversorgung. Es fehlen Mrd. Betr√§ge in der Gesetzlichen Kranken- &amp; der Pflegeversicherung\n",
      "Tweet:  -   Keine Rentenk√ºrzungen\n",
      "-   Keine Anhebung des Renteneintrittsalters\n",
      "-   Einstieg in teilweise Kapitaldeckung der Gesetzlichen Rentenversicherung.\n",
      "-   Abschaffung von Hartz IV! Stattdessen Einf√ºhrung von B√ºrgergeld.\n",
      "-   Erhalt der privaten Kranken- und Pflegeversicherung.\n",
      "(4/7)\n",
      "\n",
      "\n",
      "Query: Bundeswehr Afghanistan Krieg stoppen\n",
      "Tweet:  Nach dem Scheitern des 20-j√§hrigen @NATO-Krieges in #Afghanistan die #Bundeswehr zur√ºck an den Hindukusch schicken zu wollen, um den Vormarsch der #Taliban zu stoppen, ist der Gipfel an Hilflosigkeit, Unentschlossenheit und v√∂llig verantwortungslos. https://t.co/NdAM3JReOI\n",
      "Tweet:  @GermanCucumber1 @dieLinke OK, was ist das Problem? Stopp Abschiebungen nach Afghanistan? Stopp R√ºstungsexporte in Krisenregionen? Diplomatie statt Eskalation? Oder dass wir auf lange Perspektive Kriegsb√ºndnis NATO in ein B√ºndnis kollektiver Sicherheit umwandeln und die Vereinten Nationen st√§rken wollen?\n",
      "Tweet:  Ganz im Sinne #Laschet|s k√∂nnte schon morgen die n√§chste #Abschiebung nach #Afghanistan gehen - trotz Krieg, Terror, #Pandemie u der Bitte der afghanischen Regierung nach Abschiebestopp. Heuchlerisch anmutend auch die Kritik der SPD, die 40 Sammelabschiebungen mitgetragen hat! https://t.co/W7ZGgAtKSm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweets, query in zip(res, QUERIES):\n",
    "    print(\"Query:\",query)\n",
    "    \n",
    "    for tweet in tweets[\"tweets\"][:3]:\n",
    "        print(\"Tweet: \", tweet[\"_source\"][\"txt\"])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-query-expansion-tWkdo8vh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9ad3c02dd4b61e1f3ed1e38bd9b3b7a8e15a3f55cb03b1470e9f32af9138128"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
